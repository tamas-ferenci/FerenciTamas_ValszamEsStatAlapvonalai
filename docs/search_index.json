[["index.html", "A valószínségszámítás és a statisztika alapvonalai Elszó", " A valószínségszámítás és a statisztika alapvonalai Ferenci Tamás, 2021. február 26. Elszó Ez a visszavezetés a lényege a [] megoldásnak, nem a képlet. Péter Rózsa A valószínségszámítást matematikai formalizmus nélkül fogjuk tárgyalni Ez a jegyzet egy kísérlet. Kísérlet arra, hogy a valószínségszámítás és a statisztika alapjait elmagyarázza, de a nélkül, hogy ehhez matematikai formalizmust használna. Nem lesznek benne tételek, levezetések, bizonyítások, st, még a szimbolikus jelölések bevezetését is igyekeztem a lehet legszükségesebbre korlátozni. A formalizálás kell a mélyebb tárgyaláshoz, azonban sok hallgató (orvosok, szociológusok stb.) számára ezek a részek úgysem fontosak Mi motiválja ezt a kísérletet? A valószínségszámítás és a statisztika szokásos egyetemi tárgyalása matematikailag formalizált. Hol mélyebb apparátust használ, hol világosabbat, de mindenesetre végig matematizált. Ami, félreértés ne essék, teljesen érthet, hiszen mind a valószínségszámításnak, mind a statisztikának a korszer felépítése csakugyan jól formalizált, és ez elengedhetetlenül szükséges is a bonyolultabb koncepciók bevezetésével és tárgyalásához. Viszont a matematikai formalizmus azt is megnehezíti, hogy az alapkérdéseket megértsék A tapasztalatom azonban az, hogy rengeteg olyan hallgató van, orvostanhallgatók, szociológusok, biológusok, akik abba a furcsa helyzetbe kerülnek, hogy egyfell a matematikai formalizmusra sem szükségük nincsen, sem kézbentartani nem tudják, de másfell borzasztó fontos lenne, hogy az alapgondolatokat jól megértsék. Úgy érzem, hogy a matematizált tárgyalás az esetükben egy rossz kompromisszumot köt: azért, hogy a bonyolultabb dolgok is elmondhatóak legyenek (mert ahhoz tényleg kell a matematikai formalizmus, nem kérdés!), az egyszerbbeket is úgy mondja el, hogy nem értik meg azok, akiknek a bonyolultabbakra nincs szükségük. De miért ne mondjuk inkább ez az egyszerbbeket formalizáltság nélkül? Igen, így a bonyolultabbakat nem lehet elmondani, de ha egyszer ezekre úgysem lesz szükségük (illetve az érdekldk úgyis el tudják sajátítani)? Nem lenne jobb kompromisszum feláldozni a bonyolultabb dolgokat cserében azért, hogy az egyszerek jobban érthetek legyenek? Hiszek ugyanis abban, hogy a valószínségszámítás és a statisztika alapjait  amik sok szakmában az igazán fontosak!  igenis el lehet mondani matematikai formalizmus nélkül is értheten, világosan. A cél elérése érdekében igyekszem sokkal nagyobb figyelmet szentelni annak, hogy az alapgondolatok jól követhetek legyenek, több oldalról körüljárni ket, megmutatni az alkalmazásaikat, példát hozni, ahol lehet szimulációkat végezni, st, a jegyzet webes változatában interaktív vizualizációkat is mutatni. Minden visszajelzést örömmel veszek a tamas.ferenci@medstat.hu email-címen Az olvasó a kísérlet eredményét a jegyzet végére megítélheti. Én mindenesetre  különösen azért, mert ez egy kísérlet  minden visszajelzést, véleményt, kritikát a lehet legnagyobb örömmel veszek a tamas.ferenci@medstat.hu email-címen! A jegyzet weboldala (oktatási segédanyagokkal, technikai információkkal) a https://github.com/tamas-ferenci/FerenciTamas_ValszamEsStatAlapvonalai címen érhet el. "],["a-valószín-ségszámítás-röviden.html", "1 . fejezet A valószínségszámítás röviden 1.1 Mi az, hogy véletlen? 1.2 A valószínségszámítás alapfogalmai 1.3 A valószínség bevezetése 1.4 A valószínség interpretációi 1.5 A feltételes valószínség 1.6 A Bayes-tétel 1.7 A valószínségi változó", " 1 . fejezet A valószínségszámítás röviden A valószínségszámítás nem más, mint számokra átváltott józan ész. Pierre-Simon de Laplace A valószínségszámítás bizonyos értelemben a statisztika alaptudománya A statisztikusok számára a valószínség-számítás vagy  rosszabb esetben  gonosz nagytestvér, akire titokban irigykedik mindenki, mert az igazi matematika, cserében a felét nem érti az ember, vagy  jobb esetben  az a segédtudomány, de jobb lenne azt mondani: alaptudomány, amihez egy halom esetben vissza lehet nyúlni a statisztikai problémák kezelése során. A valószínségszámítás megértése tehát megkerülhetetlen (pontosabban szólva: nem érdemes megkerülni!) ahhoz, hogy az ember jól megértse a statiszikát. Nem kell valószínségszámítási szaktudósnak lenni, ellenkezleg, pár alapfogalom lesz csak igazán fontos  de azokat tényleg jól kell érteni. Éppen ezért a statisztika megértéséhez is fontos érteni az alapjait (és önmagában is érdekes!) Ez a fejezet ezt a célt szolgálja. Összhangban az Elszóval mondottakal, kerülni fogok minden matematikai formalizmust, képletet, levezetést, szépen kimondott tételt, ami tudom, hogy elkerülhetetlenül trehányságokhoz fog vezetni, ezért elre valszámos barátaink elnézését kérem, de cserében igyekszem hangsúlyozni azokat a koncepciókat, amiket fontos átlátni a késbbiekhez. (A statisztika és a valószínségszámítás viszonyára pedig még visszatérek késbb, amikor mindkett megfelel fogalmai és problémái ismertek lesznek.) 1.1 Mi az, hogy véletlen? Mert töredékes az ismeretünk, és töredékes a prófétálásunk. Szent Pál A valószínségszámítás alapfogalma a véletlen kísérlet: adott körülmények között akárhányszor megfigyelhet, de a kimenete nem mondható meg biztosan (csak az, hogy egyáltalán milyen kimenetek lehetségesek) Szokták mondani, hogy a valószínségszámítás alapfogalma a véletlen kísérlet és hogy ennek definíciója: valami, ami adott körülmények között akárhányszor végrehajtható vagy megfigyelhet, de a kimenete nem mondható meg biztosan (csak az ismert, hogy milyen kimenetei lehetségesek egyáltalán), például mert az ismereteink hiányosak, hogy pontosan meg tudjuk elre mondani a kimenetet. Valójában nagyon sokszor nem a szó szokásos értelemben vett kísérletrl van szó és az sem nyilvánvaló, hogy milyen értelemben figyelhet meg akárhányszor (pl. a beteg meggyógyul-e) Az elnevezés második szava jó szerencsétlen, mert a valószínségszámítás egy halom olyan dolgot vizsgál, ami nem kísérlet a szó szokásos tudományos értelmében, azaz nem mi hajtjuk végre, de még csak az sem világos els látásra, hogy milyen értelemben ismételhet meg akárhányszor. Az orvostudományban vizsgálhatjuk például azt, hogy egy beteg meggyógyul-e. Hogy ez nagyon sokszor tényleg olyan, ami nem mondható meg biztosan, az vitathatatlan, na de hogy kísérlet? És akárhányszor megfigyelhet?! A pszichológiából, szociológiából stb. nem csak hogy milliónyi hasonló példát lehetne hozni, de ezeken a területeken pont hogy nem tipikus, hogy kísérletet végzünk. Fogjuk fel ezt hagyományos elnevezésként, ami az olyan hétköznapi példákból jött mint a kockadobás, amit tényleg napestig ismételgethetünk azonos körülmények között, kísérletként. Az is döntés kérdése, hogy mi véletlen, aminek nem mondható meg biztosan a kimenetet (pl. a kockadobás az? elvileg nem!)  közelítés kérdése A véletlen szó viszont látszólag teljesen rendben van, ez tényleg jól megfelel nyelvileg annak, hogy a kimenete nem mondható meg biztosan. Valójában ezen is érdemes kicsit elmorfondírozni. A Mi a véletlen? kérdés nagy részét átutalom a filozófia tárgykörébe, itt most egy aspektust szeretnék érinteni: azt, hogy a válasz nagyon gyakran igazából azon is múlik, hogy mi milyen közelítési pontosságot választunk, mit hanyagolunk el és mit nem. Vegyük a kockadobást! Az elz bekezdésben is szerepelt, mint valami nyilvánvalóan jó példa a véletlenre, de ha jobban meggondoljuk, akkor igazából a kockadobás kimenete  az elbbi értelemben  nem véletlen, mert nagyon is megmondható: ha ismerjük az eldobás pillanatában a kocka sebességét, gyorsulását, a légellenálással kapcsolatos adatait, az ütközési tényezjét az asztallal találozáskor stb. akkor elvileg tökéletesen pontosan, determinisztikusan megmondható, hogy hányast fog mutatni, ehhez csak a fizikát kell tudni. Ha valaki azt gondolná, hogy ez csak ilyen elvi jelentség, akadémikus akadékoskodás, akkor gondoljon arra, hogy pár évvel ezeltt a laikus sajtóban is hír volt az az okostelefonra fejlesztett alkalmazás, amivel ha az ember levideóz egy rulettkereket, akkor még pörgés közben meg tudja jó eséllyel mondani, hogy hová fog érkezni a golyó! (Ezen képesség szerény kezdtke birtokában nagyon is gyakorlati jelentség és kevéssé akadémikus elnyökre átváltható.) Pedig hát a rulettkerék pörgetésénél ideáltipikusabb példát aligha lehet találni arra, hogy mi véletlen És tessék  ugyanazon múlt a dolog, hogy a kameraképen megkeressük a golyót, meghatározzuk a gyorsulását, ezt bedobjuk a mozgására vonatkozó fizikai egyenletekbe stb., és így egy sztochasztikus dolgot determinisztikussá teszünk. Úgyhogy fogalmazzunk úgy: a továbbiakban olyan jelenségekkel foglalkozunk, amik az aktuális közelítési szintünkön véletlenek. Persze jobb, ha ezek véletlenségét ki tudjuk küszöbölni, de akkor is kell valamit tennünk, ha erre nincs mód (mint ahogy sok esetben nincs, és a belátható jövben nem is lesz). Ekkor fog jól jönni a valószínségszámítás. 1.2 A valószínségszámítás alapfogalmai A véletlen kísérlet lehetséges kimeneteleit kimenetelnek nevezzük (pl. kockadobásnál az, hogy ) Az összes lehetséges kimenetet egybefogjuk egy halmazba (kockadobásnál \\(\\left\\{,,,,,\\right\\}\\)), ennek neve eseménytér Most hogy tisztáztuk a véletlen kísérlet tartalmát, menjünk tovább az alapfogalmak bevezetésében. Mindenekeltt szükségünk van a véletlen kísérlet lehetséges kimeneteleire, ezeket, roppant kreatív módon, hivatalosan kimenetelnek nevezzük1, kockadobásnál ilyen a  vagy a  (szándékosan nem számot írtam!). A kimenetelekbl mindig pontosan egy következik be: nem lehet az, hogy kett (nem dobhatok egyszerre -et és -at), és nem lehet az sem, hogy egy sem (nem lehet, hogy amit dobok az nem , nem , nem , nem , nem  és nem ). A lehetséges kimenetelek összességét, tehát mindent ami kijöhet a kísérletbl, eseménytérnek szokás nevezni. Valamilyen dolgokat akarok összefogni erre a jó matematikai objektum a halmaz lesz! Tehát az eseménytér egy halmaz, ami minden lehetséges kimenetelt tartalmaz. A kockadobásnál: \\(\\left\\{,,,,,\\right\\}\\). Az eseménytér lehet véges (kockadobás) vagy végtelen, ez utóbbi esetben lehet megszámlálhatóan végtelen (hányszor járt egy véletlenszeren választott magyar lakos külföldön) vagy nem megszámlálhatóan végtelen (mennyi a testtömege) A véges vagy legfeljebb megszámlálhatóan végtelen eseménytereket együtt diszkrét eseménytérnek, a nem megszámlálhatóan végtelent folytonos eseménytérnek nevezzük Ez egy meglehetsen egyszer helyzet, hiszen az eseménytér véges sok kimenetelbl áll. Bonyolultabb a szituáció akkor, ha mondjuk azt vizsgáljuk, hogy egy véletlenszeren kiválasztott magyar lakos hányszor járt külföldön életében. Ez lehet 0, 1, 2, 3, 4, de hol a vége? A válasz az, hogy sehol! Semmilyen számra nem mondhatjuk azt, hogy na, legfeljebb ennyiszer lehetett külföldön járni! (Az rossz érvelés, hogy nézzük meg, hogy mennyi az eddigi magyar rekorder. Mondjuk azt találjuk, hogy 123-szor járt külföldön és? Akkor mondhatjuk, hogy legfeljebb 123-szor lehet külföldön járni? Nyilván nem, a világon semmi akadálya nincs, hogy valaki 124-szer járjon. De akkor 124 a maximum? Nem, miért ne lehetne utána még egyet utazni.) Összességében tehát világos, hogy az nem korlátos, hogy valaki hányszor járhatott külföldön, így az eseménytér a \\(\\left\\{\\text{0-szor járt},\\text{1-szer járt}, \\text{2-szer járt},\\dots{}\\right\\}\\) halmaz. Ez tehát már végtelen halmaz! De a matematikusok úgy mondják: megszámlálhatóan végtelen, ami azt jelenti, hogy végtelen ugyan, de az elemeit fel lehet sorolni egymás után (hát persze, az elbb ezt meg is tettük). Még durvább a helyzet akkor, ha mondjuk azt kérdezzük, hogy mekkora egy véletlenszeren kiválasztott ember testtömege. Lehet mondjuk 70 kg, de lehet 70,5 is. Vagy 70,48. Vagy 70,477. Vagy 70,4779. Azaz ez is végtelen sok értéket vehet fel! (Valaki azt mondhatja, hogy de hát a mérlegen csak az egész kilogrammokat lehet leolvasni. Persze, így tényleg véges sok érték lehetséges csak, de vegyünk jobb mérleget, amin tizedek is vannak. Még jobbat, amin századok is, és így tovább. A lényeg, hogy elvileg a testtömeg bármilyen valós szám lehet, most függetlenítsük magunkat attól, hogy a méreszközünk ezt csak korlátozott pontossággal tudja lemérni, vegyük úgy, hogy a vizsgált jellemz az igazi testtömeg, mintha lenne korlátlan pontosságú mérlegünk.) Ez tehát végtelen sok lehetséges kimenet, de az elznél is jobban végtelen, abban az értelemben, hogy ezeknek az elemeit már fel sem lehet sorolni! (Azaz nem lehet megmondani, hogy egy adott értékre mi a rákövetkez. Mert egész számok körében világos, hogy 70 után 71 jön. De a valós számok között mi jön a 70 után? 70,1? Nem, mert a 70,01 közelebb van. Akkor 70,01? Nem, mert a 70,001 közelebb van. Akkor 70,001? És így tovább, szóval a valós számok jobban végtelenen vannak mint az egészek, hiszen fel sem lehet ket sorolni; ezt szokták nem megszámlálható végtelennek nevezni.) Az érdekes az, hogy az ember azt gondolná, hogy a három eset között a nagy különbség ott van, hogy az eseménytér véges vagy végtelen, az már részletkérdés, hogy mennyire  megszámlálhatóan vagy nem megszámlálhatóan  végtelen. Ez nem így van! A helyzet az, hogy a véges és a megszámlálhatóan végtelen eset kezelése nagyon hasonló, ami igazán eltér, az a megszámlálhatatlanul végtelen eseménytér. A véges, vagy legfeljebb megszámlálhatóan végtelen eseményteret diszkrét eseménytérnek, a nem megszámlálhatóan végtelen eseményteret folytonos eseménytérnek szokták nevezni. Valószínségeket nem a kimenethez fogunk rendelni, mert szeretnénk bonyolultabb dolgokhoz (pl. párosat dobtunk) is valószínségeket rendelni Kimenetekbl egyet vagy többet bepakolunk egy halmazba (pl. \\(\\left\\{,,\\right\\}\\)), ezt eseménynek hívjuk, és úgy definiáljuk, hogy bekövetkezik, ha olyan kimenetel következik be, ami benne van ebben a halmazban (Lehet egyelem halmaz is) Biztos esemény: az egész eseménytér, lehetetlen esemény: üres halmaz (gondoljuk végig, teljesen logikus elnevezések) Most, hogy ezeken túl vagyunk, jöhetnek végre a valószínségek! Ha már kimeneteleink vannak, akkor azt gondolhatnánk, hogy azokhoz szeretnénk valószínséget rendelni, például megmondani, hogy mekkora valószínséggel dobunk -et. Nem ezt fogjuk tenni! Szeretnénk ugyanis valószínséget rendelni bonyolultabb dolgokhoz is, például ahhoz, hogy páros számot dobunk. Ennek megragadásához ismét a halmazokhoz fordulunk: a kimenetelekbl egyet vagy többet bepakolunk egy halmazba, mondjuk így: \\(\\left\\{,,\\right\\}\\) ,elnevezzük ezt eseménynek és azt mondjuk, hogy egy esemény akkor következik be, ha olyan kimenetel áll el, ami az eseménynek  mint halmaznak  az eleme. Világos tehát, hogy az elbbi esemény tényleg azt jelenti, hogy páros számot dobtunk. Hasonlóképp definiálhatunk tetszleges további eseményt. Például a \\(\\left\\{,,,\\right\\}\\) esemény akkor következik be, ha -et dobunk, -t dobunk, -t dobunk vagy -et dobunk, hiszen egy esemény akkor következik be, ha olyan kimenetel jön ki, ami benne, mint halmazban benne van  magyarul elmondva ez lesz az, hogy 4-nél nem nagyobb számot dobtunk. Az eseményeket általában az \\(A\\), \\(B\\), \\(C\\),  betkkel jelöljük, például \\(A=\\left\\{,,\\right\\}\\).(De akkor azt nem is tudjuk megmondani, hogy mekkora valószínséggel dobunk -et?! Dehogynem! Vegyük azt az  egyelem!  halmazt, hogy \\(\\left\\{\\right\\}\\), és meg is vagyunk! A világon semmi nem tiltja, hogy egy eseménybe csak egyetlen kimenetelt pakoljunk be. Világos tehát, hogy ez a megközelítés csak általánosítja, kiterjeszti azt, mintha a kimentelekhez rendelnénk valószínségeket.) Természetesen az is egy esemény, ami az összes kimenetelt tartalmazza (vagyis az esemény maga az eseménytér), ezt szokták biztos eseménynek nevezni, és az üres halmaz is egy esemény, ezt pedig lehetetlen eseménynek hívjuk. Az elnevezések teljesen logikusak: a biztos esemény biztosan bekövetkezik, hiszen mindenképp olyan kimenetel jön ki, ami benne van (lévén, hogy az összes benne van), a lehetetlen pedig soha, hiszen egyetlen kimenetel sincsen benne (mivel üres halmaz), azaz bármelyik kimenetel is következik be, soha nem lesz igaz, hogy a bekövetkez kimenetel benne van. Ilyen módon események verbális mveleteinek megfeleltethetünk halmaz-mveleteket Pl. 4-nél nem nagyobb és páros számot dobunk a 4-nél nem nagyobb számot dobunk és a páros számot dobunk halmazainak a metszete: az és-nek megfelel a metszet Hasonlóan a vagy-nak az unió Ennek a megközelítésnek van még egy elnye. Mondjuk, hogy szeretnénk arról az eseményrl beszélni, hogy 4-nél nem nagyobb páros számot dobunk. Mi lesz ennek a halmaza? \\(\\left\\{,\\right\\}\\). De vegyük észre, hogy ez nem más, mint a két elz halmaz metszete! Persze, mert annak, hogy 4-nél nem nagyobb és páros azok a kimenetelek felelnek meg (azok kijövetele esetén következik be ez az esemény), amik egyszerre benne vannak abban, hogy 4-nél nem nagyobb és abban, hogy páros. Az események és-sel történ összekapcsolásának tehát megfelel az, hogy a halmazaik metszetét képezzük. Kitér megjegyzés: ha két esemény metszete üres halmaz, az magyarul azt jelenti, hogy nem következhetnek be egyszerre (például 2-nél nem nagyobbat dobunk és 4-nél nem kisebbet dobunk); ezeket szokás kizáró eseménynek nevezni. Továbbmenve, annak az eseménynek, hogy 4-nél nem nagyobb vagy páros számot dobunk a két halmaz uniója fog megfelelni, gondoljuk végig. Tehát a vagy-gyal történ összekapcsolásnál sem kell semmin gondolkoznunk, a vagy használatával kapott esemény(nek megfelel halmaz) a két esemény, mint halmaz uniója lesz. Egy szó mint száz, azt látjuk, hogy az események ilyen verbális képzésének megfeleltethetünk szokásos halmazelméleti mveleteket. Miért nem rendelünk egész egyszeren az összes lehetséges eseményhez valószínséget? Diszkrét eseménytérnél mködne, de folytonosnál nem, ott csúnya dolgok történnének, ha ezt megpróbálnánk Éppen ezért bevezetünk egy halmazt, mely azokat az eseményeket tartalmazza, amelyekhez egyáltalán szeretnénk valószínséget rendelni, ezt hívjuk a megfigyelhet események halmazának A végére még egy, de fontos megjegyzés. Valaki ezen a ponton esetleg azt mondhatja, hogy ne is gondolkozzunk azon, hogy mely eseményekhez rendelünk valószínséget, egyszeren vegyük a kimenetelekbl képezett összes lehetséges halmazt (az üres halmazt, az összes kimenetelt mint egyelem halmazt, az összes két kimenetelbl álló eseményt, és így tovább, egészen az összes öt kimenetelbl álló halmazig, és végül az egész eseménytérig). És akkor nem kell semmin gondolkoznunk, bárkinek bármilyen esemény jut is az eszébe, mindegyikhez lesz valószínség. Ez nagyon csábítóan hangzik  de sajnos nem fog mködni. Hogy egész pontos legyek, diszkrét eseménytereknél mködik, ott nyugodtan csinálhatjuk ezt, de folytonos esetekben nagyon csúnya dolgok történnének, ha megpróbálnánk szó szerint minden elképzelhet eseményhez valószínséget rendelni. Éppen ezért be kell vezetnünk még egy fogalmat: azon események halmazát, amihez szeretnénk egyáltalán valószínséget rendelni. Diszkrét esetben ez lehet az összes lehetséges esemény, de folytonos esetben szkebb lesz nála. A dolgot nem tehetjük meg akárhogy, bizonyos követelményeket ki kell elégítenünk (csak példának okáért: ha két eseményhez rendelünk valószínséget, akkor kötelez az uniójukhoz, tehát a vagy-gyal összekapcsoltjukhoz is rendelni valószínséget, de igaz lesz az is, hogy az és-sel összekapcsoltjukhoz is kell legyen valószínség rendelve), de ez most számunkra nem annyira fontos, a lényeg, hogy lesz egy halmazunk, amikben azok az események vannak, amikhez valószínséget rendelünk. Hívjuk ezt a megfigyelhet események halmazának. (Ez inkább csak terminológia, ne akarjunk szükségképp a megfigyelés hétköznapi szavával kapcsolatba hozni. Fogjuk fel úgy, hogy ez egy elnevezés, egyszeren így hívjuk azokat az eseményeket, amikhez valószínséget fogunk rendelni.) 1.3 A valószínség bevezetése A valószínség egy függvény, amely a megfigyelhet események mindegyikéhez hozzárendel egy valós számot (pl. \\(\\left\\{,,\\right\\}\\mapsto0,\\!3\\), ekkor \\(0,\\!3\\) valószínséget rendeltünk ehhez az eseményhez, köznyelvileg ezt 30%-nak mondjuk) Jele \\(\\mathbb{P}\\), elbbi példánkban \\(\\mathbb{P}\\left(A\\right)=\\mathbb{P}\\left(\\left\\{,,\\right\\}\\right)=0,\\!3\\) De nem akárhogy rendeljük hozzá: a valószínségek nemnegatívak, a biztos esemény valószínsége 1, és kizáró események uniójának a valószínsége a valószínségeik összege (ez utóbbi is jól érthet, ha a valószínségre mint pacák területére gondolunk egy festvásznon) Ezek axiómák (nem levezethetek valamibl) És akkor végre: jöhet a valószínség! A fentiek után a dologban nem lesz sok meglepetés: a valószínség egy függvény, amely a megfigyelhet események mindegyikéhez hozzárendel egy valós számot. Például lehet egy ilyen hozzárendelés egyik eleme az, hogy \\(\\left\\{,,\\right\\}\\mapsto0,\\!3\\). Azaz a párosat dobunk eseményhez 0,3 valószínséget rendelünk. (Hétköznapi szóhasználatban azt mondanánk: 30%. A kett ugyanaz, hiszen a százalékjel egyszeren egy szorozva 0,01-gyel-t helyettesít. A valószínségszámításban, matematikában egyszerbb az élet, ha 0,3-at mondunk.) A valószínség jele2 \\(\\mathbb{P}\\), tehát \\(A\\) esemény valószínséget \\(\\mathbb{P}\\left(A\\right)\\)-val jelöljük, elbbi példánkban: \\(\\mathbb{P}\\left(A\\right)=\\mathbb{P}\\left(\\left\\{,,\\right\\}\\right)=0,\\!3\\). És meg is vagyunk, ez a valószínség! Ez eddig igazán nem agysebészet, de az érdekes rész most jön. 1933-ban Kolmogorov szovjet matematikus azt mondta, hogy három dolgot követeljünk meg ettl a függvénytl. Tehát ne akárhogy rendeljünk valószínségeket a megfigyelhet eseményekhez, hanem csak az lesz elfogadható hozzárendelés, ami a következ három dolgot tudja: A valószínségek nemnegatívak (nem lehet olyan, hogy például \\(\\left\\{,,\\right\\}\\mapsto- 0,\\!2\\)). A biztos esemény valószínsége 1 (nem lehet olyan, hogy például \\(\\left\\{,,,,,\\right\\}\\mapsto 1,\\!1\\) vagy \\(\\left\\{,,,,  , \\right\\}\\mapsto 0,\\!7\\)). Kizáró események uniójának, tehát vagy-gyal összekapcsoltjának a valószínsége a valószínségeik összege (nem lehet olyan, hogy például \\(\\left\\{,\\right\\}\\mapsto 0,\\!1\\) és \\(\\left\\{,\\right\\}\\mapsto 0,\\!2\\), de közben \\(\\left\\{,,,\\right\\}\\mapsto 0,\\!4\\)). Magyarázatot igazából csak a legutolsó követelmény érdemel, a másik kett megfelel annak, amit a valószínség fogalomról hétköznapilag is mondanánk. A harmadik követelmény megértéséhez a legjobb, ha úgy gondolunk az eseményekre mint pacákra egy festvásznon. Még jobb, ha úgy vesszük, hogy a kimenetelek pontok, és az események, a pacák, úgy készültek, hogy egy vagy több pontot lefestettünk adott színnel. Egy jó elképzelés, és nem csak a szemléletesség kedvéért, hanem mélyebb értelemben is, ha a valószínségre úgy gondolunk, mint a pacák területére. (Ez az els két axiómát is szépen hozza: az els azt mondja, hogy egy festékpaca területe nem lehet negatív, a második pedig azt, hogy a festvászon teljes területét nevezzük 1-nek.) A kizáró esemény ebben az analógiában azt jelenti, hogy két paca nem fed át egymással, az események uniója pedig az a paca, melyben színvak módon nézzük a pacákat; így a 3. követelmény azt mondja, hogy két paca együttesének a területe a külön-külön vett területeik összege  ha nem fednek át. (Világos, hogy átfed pacáknál ez nem teljesül, hiszen ilyenkor, ha egyszeren összeadjuk a két paca külön-külön vett területét, akkor az átfed részt kétszer is beszámoltuk.) Nagyon fontos volt az a kifejezés, hogy Kolmogorov azt mondta: ezek a követelmények nem vezethetek le semmibl, nem következményei valamilyen megfontolásnak, nem lehet matematikai úton elállítani ket. Azért használjuk ket, mert ha nem ezt tennénk, akkor maga Andrej Nyikolajevics Kolmogorov nézne ránk szúrós szemmel a felh szélérl amin most lógatja a lábát, ezt pedig igazán nem akarhatjuk. Az ilyen, bizonyítás nélkül elfogadott állításokat szokás axiómának nevezni; amirl tehát most szó van, az a valószínségszámítás Kolmogorov-féle axiómákon alapuló felépítése3. Létjogosultságát az adja, hogy ezt a jegyzetet az ember elolvashatja egy mobiltelefonon, ami mobilneten keresztül hozta be, miközben zenét hallgat rajta, és azért tudja, hogy merre kell sétálnia, mert egy Föld körül kering mholdakról sugárzott jelbl a mobilja néhány méteres pontossággal meg tudta határozni, hogy hol van. Nem kell magyarázni, hogy ezek mindegyike elképeszten mély sztochasztikát (is) igényel és a mellékelt ábra szerint meglehetsen jól mködik. Semmi másra nincs tehát szükségünk, ebbl a háromból axiómából létrehozható a valószínségszámítás egész építménye. 1.4 A valószínség interpretációi A valószín az, ami legtöbbször megtörténik. Arisztotelész Valószínség interpretácója: a fenti matematikai konstrukciónak mi köze van valós jelenségekhez Legfontosabb interpretáció: elkezdünk kockát dobálgatni, és számoljuk a 2-es dobások relatív gyakoriságát Azt fogjuk tapasztalni, hogy ez konvergál valamihez  ez a valami legyen a valószínség! Ez a valószínség frekventista interpretációja Azért bven van további interpretációknak is hely (pl. ..30% a valószínsége annak, hogy holnap esni fog az es) Nagyon fontos látni, hogy ez eddig egy tisztán matematikai konstrukció volt, nem kellett, hogy bármi köze legyen a valósághoz. Mondhatom azt, hogy egy szabályos kockával dobva \\(\\left\\{\\right\\}\\mapsto 0,\\!9\\), és tessék, nem történt semmi. Nem robbant fel a számítógép, fel lehet erre is építeni egy valószínségi modellt (mindaddig természetesen, amíg a három axiómát betartjuk!). persze azért mi szeretnénk, hogy a modelljeinknek netán valami köze is legyen a valóságos jelenségekhez. Azt szeretnénk, hogy vonatkoztatható legyen a valóságra, az elméleti konstrukciónkat tudjuk valamilyen kézzelfogható dologként értelmezni. Ezt szokás a valószínség intrepretációjának nevezni. Ezzel megint részint a filozófia tárgykörébe kerülünk, amit ismét alapveten el fogok kerülni, e helyütt talán elég egy ilyen interpretációt megemlíteni  részben, hogy érthet legyen, hogy fogalmilag mit jelent az, hogy a valószínség interpretációja, részben mert ez az egyik legérthetbb, és részben mert a gyakorlatban is ezt használják a legtöbbször (beleértve a statisztikai alkalmazásokat is). Ez a valószínség frekventista interpretációja, aminek az alapgondolata borzasztóan egyszeren elmondható. Fogjunk egy dobókockát és kezdjük el dobálgatni, feljegyezve, hogy hányszor dobtunk  mondjuk  2-est. Nevezzük ezt a 2-es dobás gyakoriságának4 a kísérletsorozatunkban. Ez önmagában nem túl izgalmas: nyilván annál nagyobb lesz, minél hosszabb a kísérletsorozat, tehát minél többször dobtunk. Nézzük inkább azt, hogy az esetek mekkora hányadában dobtunk 2-est, tehát a gyakoriságot összuk el a dobások számával; ezt szokás relatív gyakoriságnak nevezni. Ha ezt ábrázoljuk grafikusan a dobások számának függvényében, akkor valami ilyesmit kapunk: (Én ezt persze most számítógépen szimuláltam, azonban bármilyen elképeszt, de a hskorban, a 18. században tényleg végrehajtottak ilyen és ehhez hasonló kísérletsorozatokat kézzel, majd ábrázolták az eredményt mint itt!) Azt látjuk tehát, hogy a relatív gyakoriság, szemben a sima gyakorisággal, nagyon is izgalmasan viselkedik: úgy tnik, hogy az értéke konvergál valamihez! Ha ezt sokszor megismételjük, akkor mind hasonló képet kapunk, a relatív gyakoriság  ebben a példában  \\(1/6\\)-hoz tart. Fordítva megfogalmazva azt is mondhatjuk: a relatív gyakoriság értéke ingadozik valamilyen érték, mint itt az \\(1/6\\) körül  és a frekventista interpretáció azt mondja, hogy ez az érték épp a valószínség lesz. Nagyon egyszeren szólva tehát a frekventista interpretáció a következ: a valószínség az, amihez a relatív gyakoriság tart! Ennek az interpretációnak késbb még sok egyéb vetülete is lesz, de számunkra most ennyi elég: a valószínség absztrakt, matematikai fogalmát hozzáhorgonyoztuk valamilyen tényleges valóságban tapasztalható, fizikai jelenséghez. Hiszen a frekventista interpretáció így azt mondja: ha tudni akarjuk egy esemény valószínségét, akkor végezzünk egy jó hosszú kísérletsorozatot, számoljuk az esemény relatív gyakoriságát, és nézzük meg, hogy ez mihez tart. Szabályos kockánál azt fogjuk tapasztalni, hogy minden kimenet azonosan \\(1/6\\) valószínség, és hogy bármely esemény valószínsége a benne lév kimenetek darabszáma szorozva \\(1/6\\)-dal. (Tehát például a páros dobás valószínsége \\(3 \\cdot\\frac{1}{6}=3/6=1/2\\), annak valószínsége, hogy a dobott szám 5 vagy annál nagyobb \\(2 \\cdot\\frac{1}{6}=2/6=1/3\\).) Ahogy mondtam, a további interpretációkról nem akarok itt beszélni, de talán azért arra érdemes felhívni a figyelmet, hogy miért vannak egyáltalán további interpretációk, milyen problémáig vannak a frekventista iskolának. Egyetlen illusztráció, csak gondolatébresztés gyanánt: teljesen természetesnek vesszük, ha a híradó végén az idjárásjelentés azt mondja, hogy 30% a valószínsége annak, hogy holnap esni fog az es. De gondoljuk csak jobban végig, milyen értelemben beszélünk itt valószínségrl? Frekventista értelemben? Azaz ha nagyon sokszor kipróbálnánk, hogy holnap esik-e az es, akkor a próbák nagyjából 30%-ában találnánk azt, hogy esik az es? 1.5 A feltételes valószínség Alapkérdés: hogy tudunk valószínségbe valamilyen információt beépíteni Ha tudjuk, hogy valami megtörtént, az hogyan módosítja a valószínséget Pl. feltéve, hogy legfeljebb 3-ast dobtunk, mennyi annak a valószínsége, hogy párosat dobtunk? Bár ez a fogalom csak valamilyen technikai apróságnak tnhet, valójában egy borzasztó fontos koncepcióról van. Az alapkérdés az, hogy hogyan tudunk a valószínségbe valamilyen ismert információt beépíteni. Más szóval, ha tudjuk, hogy valami megtörtént, akkor ezen információ fényében hogyan módosul események valószínsége? Hiszen ha van valamilyen részleges információnk, az nagyon is befolyásolhatja a valószínségét egy eseménynek, például megtudjuk azt, hogy a dobott szám 3 vagy annál kisebb, az módosítja annak a valószínségét, hogy párosat dobtunk (ahhoz képest mintha nem tudnánk semmit). Az elnevezés nagyon szerencsés, hiszen ezt úgyis kiolvashatuk: feltéve, hogy legfeljebb 3-ast dobtunk, mennyi annak a valószínsége, hogy párosat dobtunk? A matematikusok így szoktak beszélni, de ehhez mindig tartsuk észben, hogy a feltéve szót az elbbi értelmeben kell venni: ha ismerjük azt az információt, hogy legfeljebb 3-ast dobtunk, akkor ennek figyelembevételével, azaz ennek fennállása esetén mennyi a valószínsége a páros dobásnak. Lényegében az a kérdés, hogy valamilyen állítást igaznak fogadva el (legfeljebb 3-ast dobtunk), erre szorítkozva, tehát leszkítve a világunkat arra, ahol ez igaz, ezen belül mekkora a páros dobás valószínsége. Arra szkítve a világunkat, ahol a legfeljebb 3-at dobtunk megtörtént, ezen a világon belül mekkora a páros dobás valószínsége? Nagyon jól megérezhet a megoldás, ha a pacás analógiára gondolunk: az egyik pacán belül mekkora a másik paca területe? Ez a legutolsó megfogalmazás már az utat is mutatja a számításhoz. Nevezzük \\(A\\)-nak azt az eseményt, aminek a valószínségére kíváncsiak vagyunk (az elz példában \\(A=\\left\\{,,\\right\\}\\)), \\(B\\)-nek pedig a feltételét, tehát amirl tudjuk, hogy megvalósult (\\(B=\\left\\{,,\\right\\}\\)). Mi a valószínsége, hogy párosat dobtunk, feltéve, hogy legfeljebb 3-ast dobtunk? Abban a világban vagyunk, amiben igaz, hogy legfeljebb 3-ast dobtunk, és azt kérdezzük, hogy  ezen belül!  mekkora valószínséggel dobtunk párosat. A kérdés megválaszolásához legjobb a festvászonra rajzolt pacás analógia, ahol az események a pacák, és a valószínség pedig az, hogy a paca a vászon mekkora részét teszi ki. (Hiszen a pacának a területét mérjük, mégpedig úgy, hogy 1-nek a vászon területét neveztük.) Mit mondtunk most? Azt, hogy abban a világban vagyunk, amiben a \\(B\\), a feltétel teljesült, erre szkítjük magunkat. Ez tehát azt jelenti, hogy a festvászon helyett a világunkat a \\(B\\) pacára szkítjük le, és azon belül kérdezzük, hogy mekkora \\(A\\) területe. Mivel ez utóbbi (\\(B\\)-n belül \\(A\\) területe) nem más, mint \\(A\\) és \\(B\\) közös területe, így a kérdésünk egyszeren annyi: \\(A\\) és \\(B\\) paca közös része \\(B\\) mekkora részét  nem a vászon mekkora részét  teszi ki! Ami persze nem más, mint \\(A\\) és \\(B\\) közös területe osztva \\(B\\) teljes területével: Így a feltételes valószínség definíciója: \\[ \\mathbb{P}\\left(A \\mid B\\right) = \\frac{\\mathbb{P}\\left(A,B\\right)}{\\mathbb{P}\\left(B\\right)}, \\] Így tehát kapjuk a feltételes valószínség definícióját, melyet úgy jelölünk, hogy \\(\\mathbb{P}\\left(A \\mid B\\right)\\), ahol \\(A\\) valószínségét kérdezzük és \\(B\\) a feltétel: \\[ \\mathbb{P}\\left(A \\mid B\\right) = \\frac{\\mathbb{P}\\left(A,B\\right)}{\\mathbb{P}\\left(B\\right)}, \\] ahol \\(A,B\\)-vel jelöltük azt, hogy \\(A\\) és \\(B\\) (így a valószínségüket a \\(\\mathbb{P}\\left(A,B\\right)\\) jelöli). Ismert információ (\\(B\\)) beépítésével frissítettük \\(A\\) valószínségét \\(\\mathbb{P}\\left(A\\right)\\) a valószínség a plusz-információ megismerése eltt, ezért neve prior valószínség, \\(\\mathbb{P}\\left(A \\mid B\\right)\\) a valószínség a plusz-információ megismerése után, ezért neve poszterior valószínség Így lehet tehát egy ismert információ (\\(B\\)) beépítésével úgymond pontosítani egy valószínséget! \\(\\mathbb{P}\\left(A\\right)\\) a valószínség mieltt megtudnánk bármilyen plusz-információt, szokták emiatt ezt prior valószínségnek nevezni, \\(\\mathbb{P}\\left(A \\mid B\\right)\\) pedig a valószínség miután megtudtuk \\(B\\)-t, szokták ezt ezért poszterior valószínségnek nevezni. A feltételes valószínséggel tehát be tudjuk építeni az új ismeretet valamilyen valószínségi kérdés megválaszolásába. Az elbbi példánkat folytatva, szabályos kockánál annak a valószínsége, hogy párosat dobunk és legfeljebb 3-ast dobunk (\\(\\mathbb{P}\\left(A,B\\right)\\)) \\(1/6\\), hiszen az egyetlen kimenet aminél elfordul az a 2-es dobás, és emlékezzünk vissza, hogy szabályos kockánál egy esemény valószínsége a benne lév kimenetek darabszáma szorozva \\(1/6\\)-dal. Annak a valószínsége, hogy legfeljebb 3-ast dobunk (\\(\\mathbb{P}\\left(B\\right)\\)) ugyanezen logikával \\(3/6=1/2\\), így a keresett feltételes valószínség: \\(\\frac{1/6}{3/6}=1/3\\). A kérdésünket tehát most már meg tudjuk válaszolni: annak a valószínsége, hogy párosat dobtunk, feltéve, hogy legfeljebb 3-ast dobtunk \\(1/3\\). (Észrevehet, hogy az osztásnak nincs értelme, ha \\(\\mathbb{P}\\left(B\\right)=0\\). De hát ez logikus is: egy 0 valószínséggel bekövetkez eseménynél nincs sok teteje egy olyan kérdésnek, ami úgy kezddik, hogy feltéve, hogy ez bekövetkezik.) Átrendezve: \\(\\mathbb{P}\\left(A,B\\right)=\\mathbb{P}\\left(A \\mid B\\right)\\cdot \\mathbb{P}\\left(B\\right)\\) Együttes egyenl feltételes, szorozva a feltétel valószínségével A fenti definíciót átrendezhetjük a következ formába: \\(\\mathbb{P}\\left(A,B\\right)=\\mathbb{P}\\left(A \\mid B\\right)\\cdot \\mathbb{P}\\left(B\\right)\\). Ez kiolvasva azt mondja, hogy két esemény együttes bekövetkezésének a valószínsége egyenl a feltételes valószínséggel szorozva a feltétel valószínségével. Persze az együttes valószínség szimmetrikus (\\(A,B\\) ugyanaz, mint \\(B,A\\), hiszen az nyilván mindegy, hogy azt mondom, hogy \\(A\\) és \\(B\\) is bekövetkezett vagy azt, hogy \\(B\\) és \\(A\\) is bekövetkezett), \\(\\mathbb{P}\\left(A,B\\right)=\\mathbb{P}\\left(B,A\\right)\\), ezért nyugodtan írhatjuk ezt is: \\(\\mathbb{P}\\left(A,B\\right)=\\mathbb{P}\\left(B \\mid A\\right)\\cdot \\mathbb{P}\\left(A\\right)\\). Ha \\(\\mathbb{P}\\left(A \\mid B\\right)=\\mathbb{P}\\left(A\\right)\\): \\(B\\) ismerete nem változtatja meg \\(A\\) valószínségét, ilyenkor azt mondjuk, hogy ezek független események Szimmetrikus: ha ez fennáll, akkor \\(\\mathbb{P}\\left(B \\mid A\\right)=\\mathbb{P}\\left(B\\right)\\) is És mindezek egyenértékek azzal, hogy \\(\\mathbb{P}\\left(A,B\\right)=\\mathbb{P}\\left(A\\right)\\cdot \\mathbb{P}\\left(B\\right)\\) Külön említést érdemel, ha két eseményre teljesül, hogy \\(\\mathbb{P}\\left(A \\mid B\\right)=\\mathbb{P}\\left(A\\right)\\). Ez magyarán azt jelenti, hogy \\(B\\) ismerete nem változtatta meg \\(A\\) valószínségét: az új információ se nem csökkentette, se nem növelte \\(A\\) fennállásának a valószínségét. Ilyenkor szokták azt mondani, hogy \\(A\\) és \\(B\\) független események5. A páros dobás és a legfeljebb 3-as dobás tehát nem független események: \\(1/2\\) a valószínsége annak, hogy párosat dobunk (önmagában, semmi mást nem tudva), de \\(1/3\\), ha tudjuk, hogy legfeljebb 3-ast dobtunk, tehát erre feltételezünk. A páros dobás valószínsége tehát megváltozott, a poszterior valószínsége nem ugyanaz mint a prior valószínsége. Azonban párosat dobunk és a legfeljebb 2-t dobunk már függetlenek: a legfeljebb 2-t dobtunk ismeretében ugyanúgy \\(1/2\\) a páros dobás valószínsége, mint ezen ismeret nélkül. Helyettesítsük be a függetlenség definícióját a feltételes valószínség definíciójába: \\(\\mathbb{P}\\left(A \\mid B\\right) =\\mathbb{P}\\left(A\\right)= \\frac{\\mathbb{P}\\left(A,B\\right)}{\\mathbb{P}\\left(B\\right)}\\). A második egyenlségjel két oldalát véve és \\(\\mathbb{P}\\left(B\\right)\\)-vel beszorozva azt kapjuk, hogy ha két esemény független, akkor \\(\\mathbb{P}\\left(A,B\\right)=\\mathbb{P}\\left(A\\right)\\cdot \\mathbb{P}\\left(B\\right)\\). Független események együttes bekövetkezésének a valószínsége a külön-külön vett valószínségeik szorzata. Ebbl az alakból még egy dolog látható rögtön. Ha a \\(\\mathbb{P}\\left(A,B\\right)=\\mathbb{P}\\left(A\\right)\\cdot \\mathbb{P}\\left(B\\right)\\) egyenlség mindkét oldalát \\(\\mathbb{P}\\left(B\\right)\\)-vel osztjuk le, akkor kapjuk azt, amivel indítottunk, hogy ti. \\(\\mathbb{P}\\left(A \\mid B\\right)=\\mathbb{P}\\left(A\\right)\\). De teljes mértékben jogunkban áll \\(\\mathbb{P}\\left(A\\right)\\)-val leosztani, ez esetben azt kapjuk, hogy \\(\\mathbb{P}\\left(B \\mid A\\right)=\\mathbb{P}\\left(B\\right)\\). (Ne feledjük, ha egy együttes valószínséget leosztunk az egyik tag valószínségével, akkor feltételes valószínséget kapunk: a másik tag feltételes valószínségét feltéve azt, amivel leosztottunk.) Tehát a függetlenség \\(\\mathbb{P}\\left(A \\mid B\\right)=\\mathbb{P}\\left(A\\right)\\) definíciója automatikusan jelenti azt, hogy szükségképp egyúttal \\(\\mathbb{P}\\left(B \\mid A\\right)=\\mathbb{P}\\left(B\\right)\\)  azaz a függetlenség valószínségi fogalma szimmetrikus, ha az egyik esemény független a másiktól, akkor a másik is független az egyiktl. 1.6 A Bayes-tétel Egy nagy hír  és tényleg rettent fontos  tétel fog következni, ami azonban grandiózussága ellenére valójában pofon egyszeren kihozható, tulajdonképpen csak a feltételes valószínség definícióját kell kétszer alkalmazni. Egyfell ugye azt mondtuk, hogy \\(\\mathbb{P}\\left(A \\mid B\\right) = \\frac{\\mathbb{P}\\left(A,B\\right)}{\\mathbb{P}\\left(B\\right)}\\), másrészt azt is megállapítottuk  persze ugyanebbl levezetve! , hogy \\(\\mathbb{P}\\left(A,B\\right)=\\mathbb{P}\\left(B \\mid A\\right)\\cdot \\mathbb{P}\\left(A\\right)\\). Tulajdonképpen semmi másra nincs szükségünk, mint hogy összerakjuk a kettt, a másodikból származó \\(\\mathbb{P}\\left(A,B\\right)\\)-t beírjuk az els számlálójába: \\[ \\mathbb{P}\\left(A \\mid B\\right) = \\frac{\\mathbb{P}\\left(B \\mid A\\right)\\cdot \\mathbb{P}\\left(A\\right)}{\\mathbb{P}\\left(B\\right)}. \\] És ennyi, ezzel meg is kaptuk a híres-nevezetes Bayes-tételt! A nevét Thomas Bayesrl, egy 18. századi angol presbiteriánius lelkészrl kapta, aki elször alkalmazta ezt az elvet (igaz, írásban csak halál után jelent meg az errl szóló közleménye). Miért fontos ez a tétel? Rögtön megértjük, hogy mire használható, ha a két végét nézzük: egyik oldalon \\(\\mathbb{P}\\left(A \\mid B\\right)\\) van, a másikon \\(\\mathbb{P}\\left(A\\right)\\). Mit mondtunk? \\(\\mathbb{P}\\left(A\\right)\\) az \\(A\\) esemény valószínsége anélkül, hogy bármi többet tudnánk, \\(\\mathbb{P}\\left(A \\mid B\\right)\\) pedig a valószínsége \\(B\\) ismeretében, tehát beépítve azt az információt, hogy \\(B\\) megtörtént. Azaz: a Bayes-tétel az, ami ténylegesen lehetvé teszi egy információ beépítését a valószínségbe! Használva a korábban bevezetett szép kifejezéseket: lehetvé teszi, hogy a prior valószínségekrl  az információ felhasználásával  áttérjünk a poszterior valószínségekre. Késbb bven látunk még arra példát, hogy ennek miért van hatalmas jelentsége; most nézzünk illusztráció gyanánt egy nem statisztikai példát! Legyen \\(A\\) az, hogy egy vizsgált személy szenved egy betegségben, \\(B\\) pedig az erre vonatkozó pozitív lelet. Amennyiben az orvosi diagnosztika biztos lenne (ami  vegyük észre  azt is jelenti, hogy nem sztochasztikus!), azaz a pozitív lelet azt jelenti, hogy biztosan betegek vagyunk, a negatív pedig azt, hogy biztosan nem, akkor semmi probléma nincs, és nincsen szükség valószínségszámításra. Sajnos azonban a legtöbb esetben nem ez a helyzet: a teszt néha még egészséges embernél is pozitív lesz, és néha betegnél is negatív. (Tökéletlen ismeretek, ugyebár!) Az, ha ebben a helyzetben végiggondoljuk a Bayes-tételt, egyúttal egy gyakorlatban is sok meglepetést okozó helyzetre is felhívja a figyelmet. Nézzünk egy konkrét esetet! A kullancs terjesztette betegségek közül kett igazán fontos a gyakorlatban, a kullancs terjesztette agyvelgyulladás és a Lyme-kór. Ez utóbbi lesz kis példánk alanya. A Lyme-kór diagnosztizálása sajnos nem könny feladat. Különféle okokból kifolyólag a kórokozó közvetlen kimutatása általában nem lehetséges, ezért ún. szerológiai vizsgálatot végeznek, mely a kórokozó jelenlétére adott immunválaszt igyekszik kimutatni. Sajnos emiatt az egészséges emberek egy részében is pozitív lesz a teszt, például mert korábban átesett fertzésen, de az immunológiai jelei még nem múltak el, ezt fogja a teszt  hibásan  jelenleg is zajló betegségnek hinni. A jelenleg legjobb tesztekkel nagyjából 99% csak annak a valószínsége, hogy egy egészséges embernél tényleg negatív leletet ad, tehát az esetek 1%-ában fordul el az elbb leírt tévedés. Hasonlóképp, néha az is elfordul, hogy egy beteg embert tévesen egészségesnek minsít, például mert a vizsgálat idpontjában még nem alakult ki az immunválasz, így hiába beteg az alany, a teszt azt fogja hinni, hogy nincs baja. A jelenleg legjobb tesztekkel mintegy 90% annak a valószínsége, hogy egy beteg alanynál tényleg pozitív lesz a teszt, 10% valószínséggel téved, és a betegnél hibásan negatív leletet ad. Vegyük észre, hogy ezek a számok mind feltételes valószínségek! 99% a valószínsége, hogy egészséges embert egészségesnek minsít? Ez tehát azt jelenti, hogy feltéve, hogy egészséges az alany, 99% a valószínsége, hogy negatív lesz a lelet. Hasonlóképp: 1% a valószínsége  az elbbibl adódóan , hogy egészséges alanynál tévesen pozitív leletet ad. Ezt pedig úgy mondhattuk volna, hogy jobban látszódjon, hogy mitl feltételes valószínségrl van szó: feltéve, hogy egészséges az alany, 1% a valószínsége, hogy pozitív lesz a lelet. 90%, hogy feltéve, hogy betegek vagyunk pozitív a lelet, és 10%, hogy feltéve, hogy betegek vagyunk mégis negatív a lelet. Ez tehát mind feltételes valószínség, ahol arra feltételezünk, hogy igazából mi az állapotunk, és annak a valószínségét kérdezzük, hogy a lelet milyen lesz. Ennyi elzmény után nézzük meg a következ javaslatot: a biztonság kedvéért érdemes mindenkinek elmennie néha Lyme-kór tesztre, akkor is, ha nincsenek tünetei!. Els ránézésre nagyon szimpatikus tanácsról van szó: mindannyian tudjuk, hogy mennyire fontos a betegségek megelzése, ezerszer halljuk, hogy járjunk rendszeresen szrésekre stb. Ha azonban egy nagyon kicsit utánaszámolunk a dolognak, akkor meglep dolgokra bukkanunk. A kérdés: ha pozitív lett a Lyme-kór tesztünk (emlékezzünk vissza, igen kitn tesztrl van szó, 90% és 99% a jósága a két értelemben!), akkor mekkora valószínséggel vagyunk tényleg Lyme-kórosak? (Borzasztó tanulságos megkérdezni ismerseinket anélkül, hogy elmesélnénk nekik, hogy miért kérdezzük, csak megkérve ket, hogy zsigerbl válaszoljanak.) Az emberek túlnyomó része azt fogja mondani, hogy nagyon valószín, hogy betegek vagyunk, a legtipikusabb válaszok a 90, meg a 99% lesznek. Hiszen hát meg is mondtuk, hogy ilyen jó a teszt, akkor most igazából mi ezen a nagy kérdés? Számoljunk egy picit! Ahogy mondtuk, legyen \\(A\\) az, hogy Lyme-kórosak vagyunk, \\(B\\) az, hogy pozitív lett a szerológiai tesztünk. Mit kérdeztünk, hogy mekkora valószínséggel vagyunk betegek, ha pozitív a tesztünk? Ez épp \\(\\mathbb{P}\\left(A \\mid B\\right)\\). Az elz okfejtés hibája e ponton azonnal látszik: a 90% az nem ez, hanem az, hogy ha betegek vagyunk akkor mekkora valószínséggel lesz a teszt is pozitív, tehát \\(\\mathbb{P}\\left(B \\mid A\\right)\\)! Pont a fordított irányú valószínség! Ez tehát hibás, de akkor mi a helyes okfejtés? Erre lesz válasz a Bayes-tétel. Két dologra van szükségünk, az egyik \\(\\mathbb{P}\\left(A\\right)\\), a betegség prior valószínsége, tehát, hogy mindenféle tesztelés eltt mennyi annak a valószínsége, hogy betegek vagyunk. Erre szerencsére most könny válaszolni, ha ugyanis megfogadjuk a tanácsot, akkor ez igen jó közelítéssel annyi lesz, mint a betegek aránya az összlakosságon belül, ez ma Magyarországon kb. \\(1/1000\\). (Miért mondtam, hogy igen jó közelítéssel? Ezt nagyon fontos érteni: a betegek aránya az igazából nem más, mint a betegek relatív gyakorisága  hány beteg van: gyakoriság, mekkora az arányuk: relatív gyakoriság  és a magyar lakosság tízmilliós létszáma azt jelenti, hogy itt egy tízmillió hosszú, tehát hatalmas nagy kísérletsorozatot végeztünk, így a relatív gyakoriság már igen közel lesz a valószínséghez.) Kell még \\(\\mathbb{P}\\left(B\\right)\\), annak a valószínsége, hogy a teszt pozitív, semmit nem tudva arról, hogy egészségesek vagyunk-e. Hogyan kapjuk meg ezt? Ehhez egy pici trükköt6 be kell vetnünk: a teszt pozitív és egészségesek vagyunk, valamint a teszt pozitív és betegek vagyunk két kizáró esemény (egyszerre nem állhat fenn mindkett) így a vagy-gyal összekapcsoltjuk valószínsége a külön-külön vett valószínségeik összege. Mi a vagy-gyal összekapcsoltjuk? A teszt pozitív és egészségesek vagyunk vagy a teszt pozitív és betegek vagyunk? Azt, hogy a teszt pozitív azt felesleges kétszer leírnunk az meg, hogy betegek vagyunk vagy egészségesek vagyunk az olyan, mintha nem írtunk volna semmit, tehát összességében ez az, hogy a teszt pozitív  épp amire szükségünk van! So far, so good, ahogy a mvelt francia mondaná, akkor már csak kell annak a valószínsége, hogy a teszt pozitív és egészségesek vagyunk, meg annak, hogy a teszt pozitív és betegek vagyunk. Nindkett egy együttes valószínség, aminek nagyon megörülünk, mert rávágjuk, hogy az pedig nem más, mint a feltételes valószínség szorozva a feltétel valószínségével! Tehát annak a valószínsége, hogy a teszt pozitív és egészségesek vagyunk nem más, mint annak a feltételes valószínsége, hogy a teszt pozitív feltéve, hogy egészségesek vagyunk (ez tudjuk! 1%) szorozva annak a valószínségével, hogy egészségesek vagyunk (\\(1-1/1000=0,\\!999\\)). Teljesen hasonlóan annak a valószínsége, hogy a teszt pozitív és betegek vagyunk nem más mint annak a feltételes valószínsége, hogy a teszt pozitív feltéve, hogy betegek vagyunk (90%) szorozva annak a valószínségével, hogy betegek vagyunk (\\(1/1000\\)). Az elbbi szorzat tehát \\(0,\\!01 \\cdot 0,\\!999=0,\\!00999\\), az utóbbi \\(0,\\!9 \\cdot 0,\\!001=0,\\!0009\\), és amint megbeszéltük, a keresett valószínség egyszeren e kett összege: \\(\\mathbb{P}\\left(B\\right)=0,\\!00999+0,\\!0009=0,\\!01089\\). És ezzel minden megvan, bevethetjük a Bayes-tételt: \\[ \\mathbb{P}\\left(A \\mid B\\right) = \\frac{\\mathbb{P}\\left(B \\mid A\\right)\\cdot \\mathbb{P}\\left(A\\right)}{\\mathbb{P}\\left(B\\right)}=\\frac{0,\\!9 \\cdot 0,\\!001}{0,\\!01089}=0,\\!083. \\] Az eredmény tehát az, hogy ha pozitív a leletünk, akkor 8,3% a valószínsége annak, hogy tényleg betegek vagyunk! Nem 90, meg 99%, 8,3! A pozitív leletünk azt jelenti, hogy még 10%-ot sem éri el annak a valószínsége, hogy tényleg betegek vagyunk! Az els és legfontosabb ezen eredmény kapcsán, hogy ne úgy tekintsünk rá, hogy itt kijött egy elég megdöbbent dolog valami matematikai hókuszpókusz eredményeként. Értsük meg, hogy mi ennek a megdöbbent eredménynek az oka! Értsük a jelenség okát, ne fogadjuk el, hogy valami számok ledarálásából ez jött ki, és hát akkor ez van. Mi a hibás kezdeti benyomásunk oka? Hogy lehet, hogy miközben a teszt kitnen, 90 meg 99% jósággal mködik, de a pozitív lelet mégis 90%-nál is nagyobb valószínséggel azt jelenti, hogy igazából nem vagyunk betegek? Kezdjük az elején: az érdekel minket, hogy ha pozitív a leletünk, mekkora valószínséggel vagyunk betegek. Ki kap pozitív leletet? Az, aki beteg, és a teszt jól mködik nála, meg az, aki egészséges, de a teszt sajnos hibás eredményt ad az esetében. Hány alany jön a kétféle forrásból? Elsre azt gondolhatnánk, hogy az elbbi lesz a túlnyomó többség, hiszen ha valaki beteg, akkor a teszt 90% valószínséggel jól mködik nála, míg ha egészséges, akkor mindössze 1% valószínséggel lesz hibás. Csakhogy ez hibás logika! A kutya ott van elásva, hogy a betegség ritka, azaz nagyon alacsony a tesztelés eltti valószínsége annak, hogy betegek vagyunk, mindössze \\(1/1000\\). Emiatt ezerszer több egészségeset fogunk tesztelni, mint beteget. És ebben van a kulcs: az ezerszer több egészségesnek hiába csak 1%-a lesz pozitív, de az ezerszer több egészségesnek még az 1%-a is több, mint az ezredannyi beteg 90%-a! Ezen múlik a dolog. Kicsi a valószínsége, hogy egy egészségest elnéz a teszt, de annyival sokkal-sokkal-sokkal több egészségeset tesztelünk, hogy még ezeknek a kicsi hányada is több lesz, mint a helyesen azonosított betegek. Így végeredményben a pozitív leletet kapó betegek többsége helytelenül azonosított egészséges, és nem helyesen azonosított beteg lesz. Fontos azért azt is látni, hogy nem arról van szó, hogy a teszt rossz. A teszt bizonyos értelemben nagyon is mködött: a pozitív lelet \\(1/1000\\)-rl kb. 10%-ra, azaz két nagyságrenddel emelte annak a valószínségét, hogy tényleg betegek vagyunk! Az már egy másik kérdés, hogy nagyon alacsonyról indultunk, így az emelés utáni érték is elég alacsony lett. A példa arra is felhívja a figyelmet, hogy mennyire fontos, hogy ne keverjük össze a feltételes valószínség irányát, hogy \\(\\mathbb{P}\\left(A \\mid B\\right)\\)-rl vagy \\(\\mathbb{P}\\left(B \\mid A\\right)\\)-ról beszélünk. Amire feltételezünk, az mindig az ismert információ  hiszen a feltételes valószínség építi be ezt az információt. Ha ilyen szemmel nézzük a példát, akkor láthatjuk, hogy a 90% meg a 99%-os jóságértékek a teszt jósága szempontjából relevánsak, de a gyakorló orvosnak, aki beteget kell, hogy diagnosztizáljon, nem fontosak: az nem érdekes, hogy feltéve, hogy beteg az alany mekkora valószínséggel pozitív a teszt, hiszen ilyenkor olyasmire feltételezünk, amit az orvosi rendelben nem tudunk, és annak a valószínségét kérdezzük meg, amit tudunk! Természetes, hogy ennek pont a fordítottja kell, arra kell feltételeznünk, amit tudunk (pozitív a teszt), és annak a valószínségét kell megkérdeznünk, amit nem tudunk (beteg-e az alany). Ehhez kell a Bayes-tétel, de a fentibl látható, hogy a kett nagyon nem ugyanaz. Azért nem, mert az irány megfordításához bejön a képbe a prior valószínség. 1.7 A valószínségi változó A matematikaóra nehéz. Nem megyünk vásárolni? Barbie (1992-es Beszél Barbie kiadás) Az utolsó pont amit meg kell tárgyalnunk, tulajdonképpen a kiindulópont a valószínségszámítás mélyebb (és matematikailag is intenzívebb) tárgyalásához, itt azonban mégis csak röviden fogunk vele foglalkozni, mert a továbbiakhoz nekünk nem igazán lesz rá szükségünk. Az alapprobléma a következ: nagyon sokszor jól jön, ha a egy véletlen kísérlet eredményével valamilyen mveletet tudunk végezni. Például szeretnénk beszélni két kockadobás összegérl vagy tíz ember átlagos testtömegérl. Ez els ránézésre nyilvánvaló (ha az egyikkel 2-est dobtunk a másikkal meg 3-ast, akkor az összeg 5), de valójában nem az. A probléma, hogy a véletlen kísérlet eredménye az, hogy  meg az, hogy  ezeket pedig aligha lehet összeadni! A testtömeges példán talán kevésbé egyértelm, de ott is errl van szó, a kimenet nem az, hogy 70, hanem az, hogy 70 kg. De még világosabb, hogy mi a probléma, ha pénzérmét dobunk fel, ahol a két kimenet fej és írás, szóval ez még felületes szemlélnek sem érthet úgy, hogy magától mködnek a mveletek. Elvileg persze lehetne mindenféle mveleteket bevezetni a kimenetekre is, de minek? Egyrészt a nulláról kellene ezeket felépítenünk, másrészt minden eseménytérre külön-külön meg kellene tennünk, miközben van egy nagyon jól ismert és jól értett matematikai struktúránk az ilyen mveletek elvégzésére úgy hívják, hogy szám. Nem lenne jobb inkább azzal tördni, hogy leképezzük az eseményteret számokra, és ezzel el is van intézve a probléma? Ráadásul így egységesek lehetnénk, hiszen minden eseményteret ugyanarra az objektumra képettük le, a valós számokra. A dolog nem is tnik nehéznek: a -höz rendeljük hozzá azt, hogy 2 (mint szám), a 70 kg-hoz azt, hogy 70 (mint szám), a fej-hez azt, hogy 1 (önkényesen, itt nincs olyan természetesen hozzárendelés) és így tovább. Az ilyen leképezést, függvényt, ami minden kimenethez hozzárendel egy valós számot, valószínségi változónak nevezzük. A valószínségi változókat általában az \\(X\\), \\(Y\\), \\(Z\\),  betkkel jelöljük, tehát például egy lehetséges hozzárendelés, hogy \\(\\mapsto 2\\), amit úgy is írhatunk, hogy \\(X\\left(\\right)=2\\). (Vigyázat, nincs kapcsos zárójel! Nem az eseményhez, hanem a kimenethez rendelünk számot.) Diszkrét eseménytérnél diszkrét valószínségi változóról, folytonos eseménytérnél folytonos valószínségi változóról szokás beszélni. A valószínségi változó használatával tehát a kimeneteket leképezzük számokra, amin már jól el tudunk boldogulni. Nagyon fontos, hogy ezzel a valószínségeket is átvisszük a számokra, csak egy kis megállapodást kell tennünk: ha azt mondjuk, hogy mi annak a valószínsége, hogy \\(X=3\\), azt úgy értjük, hogy mi azon kimenetekbl álló esemény valószínsége, amely kimeneteket a valószínségi változó a 3-ba képezi (ami esetünkben egyszeren a \\(\\left\\{\\right\\}\\) valószínsége), ha azt mondjuk, hogy mi \\(X&lt;3\\) valószínsége, azt úgy értjük, hogy mi azon kimenetekbl álló esemény valószínsége, amely kimeneteket a valószínségi változó 3-nál kisebb számba képezi (jelen esetben az \\(\\left\\{,\\right\\}\\) esemény valószínsége) és így tovább. És ezzel kész is vagyunk! Mindenféle ilyen számhalmaznak, tehát adott számnak, több számnak, intervallumnak stb. meg fogjuk tudni adni a valószínségét. Ezzel \\(X\\)-re úgy is tekinthetünk mint egy számra, csak épp nem adott számra, hanem egy olyan valamire, ami többféle számot is felvehet értékül  de nem akárhogy, hanem bizonyos eloszlást követve. (Egyedül arra kell figyelnünk, hogy a valós számok közül azokhoz akarjunk valószínséget rendelni, de azokhoz mindegyikhez, amivel tényleg jól tudunk bánni  mert nem minden számhalmaz ilyen. Ez annyi megkötést jelent, hogy a jól kezelhet halmazokba képezd kimenetek legyenek megfigyelhet események, hiszen emlékezzünk vissza, a megfigyelhet események halmaza épp az, amihez valószínséget rendelünk.) Annak a valószínségét, hogy a valószínségi változó egy adott számnál kisebb, tehát \\(X&lt;x\\) valószínségét (vigyázzunk a kis- és nagybetkre! bal oldalon \\(X\\), tehát a valószínségi változó van, jobb oldalon \\(x\\), ami egy általunk megadott tetszleges valós szám) a valószínségi változó eloszlásfüggvényének szokták nevezni. Ez csakugyan \\(x\\) függvénye, hiszen minden \\(x\\)-hez megad egy valószínséget. Például szabályos kockadobásnál így néz kis: (Figyeljük meg a nyílt és zárt karikákat! Mivel azt mondtuk7, hogy \\(X&lt;x\\) valószínsége érdekel minket, ezért azokat az ábra szerinti módon kellett kirakni, például pont 1-ben még 0 lesz a függvény értéke, hiszen 0 valószínséggel kisebb a valószínségi változó mint 1.) Eloszlásfüggvénye minden valószínségi változónak, diszkrétnek és folytonosnak is van. Diszkrét valószínségi változónál azokból az számokból is csak diszkrét sok van, amihez a valószínségi változó nem nulla valószínséget rendel, így általában érthetbb képet ad, ha egyszeren ezeket ábrázoljuk: Ezt szokás a változó valószínségi súlyfüggvényének nevezni, de sokszor egyszeren csak azt mondják rá, hogy ez a változó eloszlása. Folytonos változó esetén zrsebb a helyzet: be lehet látni, hogy egy folytonos valószínségi változó minden konkrét értéket 0 valószínséggel vesz fel! (Ha valakinek ezt nem venné be a gyomra  miért ne lehetne valakinek a testtömege pont 70 kg?  az gondoljon arra, hogy a folytonos eset az olyan, mintha végtelen pontosággal mérnénk. Igen, valakinek lehet pont 70 kg a testtömege  egy kilogramm pontossággal mér mérlegelen. De ha lecseréljük egy jobb, tized kilogramm pontosságú mérlegre, akkor kiderül, hogy a 70 kg-nak mértek igazából 69,7 vagy épp 70,3 kg-osak. Persze lesz aki még így is 70, azaz 70,0, de ekkor vessünk be egy század kilogramm pontosságú mérleget. Ekkor megint kiderül egy sor emberrl, hogy igazából nem 70,00 volt a tömegük. Aki még így is 70,00 marad, azokat lemérjük egy ezred kilogramm pontosságú mérlegen és így tovább. Talán így már jobban elhihet, hogy nulla valószínség esemény, hogy valaki 70,0000000 kg súlyú legyen, ha a pontossággal a végtelenbe tartunk.) Persze ez nagyon furcsa lehet, hiszen ha minden értéket nulla valószínséggel vesz fel, akkor meg hogyan lehet, hogy valamilyen értéket mégis 1 valószínséggel vesz fel? De a végtelen ilyen furcsa dolgokat produkál: véges sok nulla összege nulla, st, végtelen soké is, ha az csak megszámlálhatóan végtelen  de nem megszámlálhatóan végtelen nulla összege lehet 1! Folytonos valószínségi változó eloszlásfüggvénye (ne feledjük, az létezik folytonos változóra is!) nézhet ki például így: Folytonos valószínségi változónál annak tehát nincs értelme, hogy milyen valószínséggel vesz fel a változó egy adott konkrét értéket (mert az minden értékre nulla), de szerencsére annak van értelme, hogy mivel arányos annak a valószínsége, hogy egy adott érték kis környezetébe esik a felvett érték. Ez egyszer mveletekkel meghatározható az eloszlásfüggvénybl; az elbbi esetben így néz ki: Olyat nem mondhatunk, hogy ez a valószínségi változó valószínbb, hogy 70 értéket vesz fel, mint hogy 40-et (mivel mindkettt nulla valószínséggel veszi fel), de olyat a legteljesebb mértékben mondhatunk, hogy valószínbb, hogy a 70 környékére esik, mint hogy a 40 környékére. Ezt a függvényt szokás a folytonos változó srségfüggvényének nevezni (érzékletes szóval: milyen srn esik a változó egy adott környékre); de itt is gyakori, hogy egyszeren csak eloszlásról beszélnek. Némelyik magyar irodalom a kimenetel helyett az elemi esemény terminológiát használja. Ez azonban nem egységes, az angol irodalom egységesen nem ezt hívja elemi eseménynek, ráadásul a kimenetel szó némileg logikusabb is, úgyhogy a továbbiakban ezt fogom használni. A könyvek egy része \\(\\mathbf{P}\\)-t használ, tehát vastagon szedi a bett. Kézírásban persze senki nem fog nekiállni satírozgatni minden betnél, ezért gyakran duplaszárú bett használnak, ami viszont nagyon menn néz ki, ezért érdekes módon visszaszivárgott a gépi szedésbe; én is ezt fogom használni. Mint azt ez a megfogalmazás is sejteti, lehetséges más axiómákból is felépíteni valószínségszámítást (akár egészen meglep módokon is, például megengedhetünk negatív valószínséget is), de az elsöpren legnépszerbb a Kolmogorov-féle axiomatizálás. Innen jön ennek az interpretációnak az elnevezése. Csak sajnálni lehet, hogy a mai értelemben vett valószínségszámítás még nem létezett a nyelvújítás korában, különben egész biztosan beszélhetnénk gyakoriságista értelmezésrl. Úgyhogy folytassuk is kalandozásunkat a viszonyatlan hihetség-számítás terén! A valószínségi értelemben vett függetlenségnek nem feltétlenül van köze a függetlenség hétköznapi értelméhez, mondjuk, hogy az egyik nem okozza a másikat: egyszeren annyit jelent, hogy \\(A\\) esemény \\(B\\)-n belüli területe \\(B\\)-hez viszonyítva ugyanannyi mint \\(A\\) egész területe a festvászonhoz viszonyítva. E trükk logikáját teljes valószínség tételének szokták nevezni. Ez a magyar  és az egykori szovjet  szokás. A nyugati irodalmak gyakran \\(X\\leq x\\) valószínségével definiálják az eloszlásfüggvényt. "],["a-következtet-statisztika-alapjai.html", "2 . fejezet A következtet statisztika alapjai 2.1 Egy rávezet gyakorlat 2.2 Egy becslfüggvény felé 2.3 A bayes-i probléma 2.4 A frekventista statisztika építménye", " 2 . fejezet A következtet statisztika alapjai A statisztika szó alatt rengeteg dolgot szoktak érteni. Statisztika annak módszertana, hogy hogyan kell az ország inflációját megbecsülni, statisztika, hogy egy piackutatást vagy közvéleménykutatást hogyan kell megtervezni és kiértékelni, statisztika, hogy 10 számból átlagot számolunk, statisztika, hogy 100 számból egy oszlopdiagramot rajzolunk. A statisztika kicsit matematizáltabb területeit két nagy csoportra szokták osztani, leíró (deskriptív) és következtet (induktív) statisztikára. Egyelre nem mondom meg, hogy ezek a szavak mit jelentenek, mert a szükséges fogalmakat csak késbb fogom bevezetni, de annyit mindenesetre elárulok, hogy a továbbiakban ez utóbbiról, a következtet statisztikáról lesz szó. (A deskriptív statisztika általában jóval érthetbb, és sokkal kevesebb kérdést vet fel.) 2.1 Egy rávezet gyakorlat Barátunktól kapunk egy pénzérmét, mely nem feltétlenül szabályos, tehát nem biztos, hogy a fej dobás valószínsége épp 0,5, azaz 50%. Lehet bármennyi, jelöljük \\(p\\)-vel, egyedül annyit kössünk ki, hogy azért nem 0 és nem 1. A feladat: meghatározni \\(p\\)-t, azaz megmondani, hogy mekkora valószínséggel dobunk fejet. Mit csináljuk? A legtöbben valószínleg mindenféle statisztikai megfontolás nélkül is azt tennék, hogy elkezdik feldobálgatni a pénzérmét, és számolják, hogy hányszor jön ki fej. Mondjuk, hogy 10-szer dobjuk fel, és 7-szor kapunk fejet. Úgy fogjuk mondani: ez lett a mintánk (a minta szó használatának oka késbb még világosabb lesz). A statisztika azon területét, ami egy megfigyelt jelenségbl igyekszik következtetni valamilyen, a jelenség hátterében lév dologra (jelen esetben a 10 dobásban kapott 7 fejbl a \\(p\\)-re) szokás induktív (vagy következtet) statisztikának mondani. Mit tudunk tehát mondani a 10 dobásból kapott 7 fej láttán? Ettl még a \\(p\\) elvileg akármennyi lehet. Furcsa lenne, ha csak mondjuk 1% lenne (és mégis 10-bl 7-szer ez jött ki), de nem lehetetlen! Számoljuk is ki, hogy \\(p=0,\\!01\\) mellett mekkora valószínséggel dobunk 10-bl 7-szer fejet. Ez esetben elsre 0,01 valószínséggel dobunk fejet, másodikra szintén, és ha e kett dobás független egymástól, akkor annak a valószínsége, hogy elsre és másodikra is fejet dobunk \\(0,\\!01 \\cdot 0,\\!01\\). (Emlékezzünk vissza, hogy független események együttes bekövetkezésének a valószínsége a külön-külön vett bekövetkezési valószínségeik szorzata!) Hasonlóképp, annak a valószínsége, ha \\(p=0,\\!01\\), hogy az els három fej lesz, nem más mint \\(0,\\!01^3\\), és annak, hogy az els 7 fej lesz, \\(0,\\!01^7\\). Pontosan 7 fejet akkor kapunk, ha a maradék 3 dobás mind írás (\\(0,\\!99^3\\)), így ennek az egész sorozatnak a valószínsége \\(0,\\!01^7 \\cdot 0,\\!99^3\\). Annak a valószínsége, hogy 10-bl 7-szer jön ki fej azonban ennél jóval nagyobb, hiszen akkor is 7-szer jön ki, ha az els, harmadik, negyedik, , nyolcadik lesz fej, akkor is, ha az utolsó 7 dobás fej stb. Némi pofozgatás után kiügyeskedhetjük, hogy ennek a valószínsége: \\(0,\\!000000000001164\\). Hát ez tényleg nem túl nagy de nem nulla! Elvileg tehát akkor is dobhatunk 10-bl 7 fejet, ha közben 1% a fej-dobás valószínsége. Más \\(p\\) választásnál azonban más lesz annak a valószínsége, hogy ha annyi az igazi \\(p\\), akkor mekkora valószínséggel jön ki 10-bl 7 fej. Például ugyenilyen módon számolva, \\(p=0,\\!02\\)-nél ez \\(0,\\!000000000144567\\), \\(p=0,\\!1\\)-nél \\(0,\\!000008748\\), \\(p=0,\\!5\\)-nél \\(0,\\!1172\\) (egyre n), \\(p=0,\\!9\\)-nél \\(0,\\!05740\\), \\(p=0,\\!99\\)-nél \\(0,\\!0001118\\) (megint csökken). Lendületbe jöttünk! Akkor már na aprózzuk el, hogy néhány \\(p\\)-nél számolgatjuk számoljuk ki nagyon srn 0-tól 1-ig és ábrázoljuk, hogy mit kapunk! Íme: Azt, hogy ha az ismeretlen paraméter valódi értéke egy adott szám lenne, akkor mekkora valószínséggel kapjuk azt, amit ténylegesen kaptunk is, likelihoodnak szokás nevezni. (Most valaki megkérdezhetné, hogy miért nem valószínségnek hívjuk, hogy egyszer ez egy valószínség. A kérdés jogos, ebben az esetben nyugodtan hívhatnánk valószínségnek is, mert a pénzfeldobás kimenete diszkrét. Ha azonban folytonos lenne, akkor is szeretnénk egy ezzel teljesen analóg fogalmat használni, amit azonban semmiképpen nem hívhatnánk valószínségnek, mert az nem valószínség, úgyhogy a likelihood szó azért jó8, hogy egy kifejezéssel lehessen egységesen mindkét esetre hivatkozni.) A fenti grafikonon tehát a 10-bl 7 fej minta likelihoodja látszik különböz \\(p\\)-k mellett. Na most akkor rakjuk össze hol tartunk. Egy: elvileg akármi lehet a \\(p\\), attól még kaphatjuk azt, amit ténylegesen kaptunk is (10-bl 7 fej) tehát biztosan nem tudjuk megmondani, hogy mi a \\(p\\), bármit is mondunk, az mindenképp tipp lesz. De kett: igenis tudunk racionálisan tippelni, mert hát csak ne tippeljük már azt a \\(0,\\!01\\)-et, ami mellett borzasztó valószíntlen, hogy 10-bl 7 jöjjön ki! Miközben épp most jött ki ez ténylegesen! St, menjünk tovább: tippeljük azt, aminek a fennállása mellett a legvalószínbb, hogy az jöjjön ki, ami ténylegesen ki is jött! Tehát ami mellett a legnagyobb a likelihoodja a ténylegesen kijött mintának. A statisztikusok nem tippelést mondanak, mert az nem sugározza e terület hideg profizmusát, úgyhogy e helyett a  csakugyan  sokkal komolyabban hangzó becslés szót használják. Amit a fentiekben láttunk, azt úgy hívják: maximum likelihood becslés, és ezek után már túl sok kommentár nemigen kell hozzá, hogy az elnevezés honnan jön: azt fogadjuk el az ismeretlen paraméter becsléseként, amely mellett a ténylegesen kijött minta likelihoodja a maximális. Mellesleg ránézve az ábrára, a maximum nagyon úgy tnik, hogy \\(0,\\!7\\), ami elég gyanúsan pont annyi, mint a fejek aránya a mintánkban 2.2 Egy becslfüggvény felé Két dolog van, aminél jobb, ha az ember nem látja hogyan készül: a kolbász és a [statisztikai] becslés. Edward Leamer A becslést most megkaptuk egy konkrét mintára. De mi van akkor, ha más a minta? Ha nem 7-szer dobunk fejet, akkor mi lesz a maximum likelihood becslés? Játszunk el egy kicsit a dologgal (azt is beállíthatjuk, hogy hányszor dobtunk): Eleget próbálkozva valószínleg mindenkiben kialakul egy benyomás: a maximum likelihood becslés mindig épp a fejek aránya a mintában, tehát a dobálgatásos kísérletsorozatunkban. Mondom a jó hírt: a dolog nem véletlen. Matematikailag bebizonyítható, hogy ez mindig így kell legyen: a maximum likelihood becslés az ismeretlen paraméterre (a fej-dobás valószínségére) a mintabeli arány lesz. Vegyük észre, hogy ezzel egy jóval ersebb eredményt értünk el, mint az elz pontban, hiszen nem egy konkrét helyzetre adtuk meg a jó becslést, hanem egy általános receptet találtunk, ami minden mintára megadja, hogy annál a mintánál mi lesz a jó becslés! A recept tehát egy általános számítási eljárás: megmondja, hogy mit csináljunk a mintában lév megfigyelésekkel (jelen esetben: számoljuk meg, hogy hány fej van benne, majd osszuk el a dobások számával), hogy megkapjuk az abból a mintából számolható becslést. Az ilyen általános receptet szép nevén becslfüggvénynek nevezzük. A valószínség maximum likelihood becslfüggvénye tehát a mintabeli arány. 2.3 A bayes-i probléma Sok nehézséget megspórolnánk, ha [a bayes-i statisztika hívei] követnék Bayes példáját, és csak a haláluk után publikálnának. Maurice Kendall Azt gondolom, hogy van jogos érv a nem bayes-i eljárások használatának védelmében, jelesül, a hozzá nem értés. John Skilling Eddig látszólag minden szép, tiszta és világos. Kézenfekv a levezetés ahogyan eljutottunk a maximum likelihood becslésig, tökéletesen logikus volt minden lépés. De nézzük csak meg jobban, hogy milyen feltételes valószínséget vizsgáltunk ott! \\(\\mathbb{P}\\left(\\text{minta}\\mid\\text{ismeretlen paraméter}\\right)\\). Ha elég sokáig és elég szúrós szemmel nézzük ezt, akkor valószínleg egyszer csak elfog minket a jeges rémület: a Bayes-tételrl szóló részben (1.6. alfejezet) pont az ilyen valószínségek használatával követtünk el kapitális hibát! Hiszen, nézzük meg, pont ugyanaz a baj itt is: arra feltételezünk, amit nem ismerünk, és annak a valószínségét kérdezzük, amit ismerünk! Ahogy már ott is láttuk, pont fordítva kellene: nem az érdekel minket, hogy az ismeretlen paraméter ismeretében mit tudunk mondani a mintáról, hanem az, hogy a minta ismeretében mit tudunk mondani az ismeretlen paraméterrl! Szerencsére épp az ott megtanultak miatt nem esünk pánikba, hiszen tudjuk mi a teend, hogy megfordítsuk a dolgot, és áttérjünk a tényleg releváns feltételes valószínségre: \\[ \\mathbb{P}\\left(\\text{ismeretlen paraméter}\\mid\\text{minta}\\right)=\\frac{\\mathbb{P}\\left(\\text{minta}\\mid\\text{ismeretlen paraméter}\\right)\\cdot \\mathbb{P}\\left(\\text{ismeretlen paraméter}\\right)}{\\mathbb{P}\\left(\\text{minta}\\right)}. \\] A számláló els tagja nem probléma: ez épp a likelihood! A nevez szintén nem probléma, a Bayes-tételnél látott trükkel itt is elintézhetjük, ha egyébként a számlálót ismerjük. De mi a helyzet a \\(\\mathbb{P}\\left(\\text{ismeretlen paraméter}\\right)\\)-rel? Próbáljuk megérteni, hogy ez mit jelent. Mi a valószínsége annak, hogy a paraméter adott érték, úgy hogy a mintát nem is ismerjük. Mit gondolunk arról, hogy milyen a fej-dobási valószínség, még mieltt egyetlen egyszer is feldobtuk volna az érmét? Valaki esetleg azt mondhatja: semmit, hát épp ezért kezdjük dobálni! Ez egy jogos ellenvetés, de egyelre rakjuk félre, vagy mondjuk azt, hogy a semmit nem gondolunk, az ezt jelenti9: Tehát: 0-nál kisebb és 1-nél nagyobb nem lehet a fej-dobási valószínség, azon belül pedig minden érték környékére ugyanakkora valószínséggel esik10. Ha azonban jobban megnézzük, akkor most egy nagyon erteljes eszközt kaptunk a kezükbe. A Bayes-tétel ugyanis lehetvé teszi, hogy felhasználjuk ha van valamilyen elzetes ismeretünk, elképzelésünk a paraméter eloszlásáról! Például az érmét egy megbízható barátunktól kaptuk, és azt gondoljuk, hogy  ha nem is biztosan  de valószínleg nem cinkelt, legalábbis nem nagyon. Ekkor a következ lehet a feltételezésünk a fej-dobás valószínségérl, még mieltt egyetlen egyszer is feldobtuk volna: Ezeket az eloszlásokat szokták  a korábban mondottak fényében nagyon is érthet szóval  prior eloszlásnak nevezni. Mit kapunk a bayes-i megközelítés eredményeként? Korábban azt írtam, hogy \\(\\mathbb{P}\\left(\\text{ismeretlen paraméter}\\mid\\text{minta}\\right)\\), de ezt némileg idézjelbe kell tenni: az ismeretlen paraméter egy folytonos dolog (bárhol lehet 0 és 1 között), tehát nem arról lesz szó, hogy mekkora valószínséggel vesz fel egy értéket, hanem eloszlása lesz. Ami tulajdonképpen teljesen logikus: van egy eloszlása a kísérletezgetésünk eltt (a prior eloszlás), és egy másik a kísérletezés után. Hát persze: a Bayes-tétel, amint láttuk, beépít egy információt, és itt is ez történt: fogja a prior eloszlást, beleépíti az információt, ami kiderült a kísérletezésünkbl, tehát a mintából, és kiköp egy frissített eloszlást, ami már a minta információját is tartalmazza. Ezt szokás  szintén logikus szóval  poszterior eloszlásnak nevezni. Például egyenletes prior esetén a következ lesz a poszterior (továbbra is mondjuk, hogy 7 fejet dobtunk 10 kísérletbl): Viszont a baráttól kaptunk a pénzérmét prior esetén így fog kinézni a poszterior pontosan ugyanazon minta mellett: A különbség nem nagy, de ha jobban megnézzük azért érzékelhet: az utóbbi esetben kicsit balra mászott a poszterior eloszlás. Miért? Azért, mert hiába láttuk azt, hogy a kísérletben meglehetsen cinkeltnek mutatkozott a pénzérme, de mi hajlunk arra egyéb (értsd: kísérletünkön kívüli) okokból, hogy a pénzérme nem annyira cinkelt, ezért bár a próbálkozásunk eléggé meggyzött az ellenkezjérl, de nem tökéletesen (nem annyira, mintha nem lett volna ilyen elzetes hiedelmünk). Tehát pontosan azt látjuk, hogy az elzetes ismeret beleépült a becslésbe! Nagyon tanulságos kipróbálni mindenféle prior és minta mellett, hogy hogyan alakul a poszterior, és hogy az hogyan viszonyul a  prior információval nem törd  maximum likelihood becsléshez. A következ grafikonon a két eloszlás mellett látható a maximum likelihood becslés is, vastagabb függleges vonallal megjelölve (azzal ne tördjünk, hogy az \\(\\alpha\\) meg a \\(\\beta\\) mit jelent, a lényeg, hogy ezek állításával a prior eloszlás alakját nagyon sokféle kinézetre beállíthatjuk): Próbálkozzunk mindenféle priorokkal (egyenletes, valahol csúcsosabb) és különböz mintákkal is (nem csak különböz fej-dobás számok, de különböz kísérlethosszak is)! Milyen tanulságokat szrhetünk le ebbl? A legfontosabbak: A prior maga felé húzza a poszteriort, ahhoz képest mint ahol a maximum likelihood becslés lenne. Ennek magyarázatát már láttuk: a poszterior egyszerre veszi figyelembe a prior információt és a dobálgatásunk kimenetét (míg a maximum likelihood becslés csak ez utóbbit). Minél csúcsosabb a prior, ez annál inkább igaz. Persze: a csúcsosabb prior azt jelenti, hogy biztosabbak vagyunk már eleve is abban, hogy ott van a paraméter értéke, kevésbé bizonytalanít el minket ebben még egy ellentmondó eredmény is. És a végére még egy nagyon fontos dolog: a prior annál jobban számít, minél kisebb volt a minta, tehát minél kevesebbszer dobtuk fel a pénzérmét. De gondoljuk meg, ez kristálytisztán logikus: rövidebb kísérlet kevesebb információt jelent (bármi is jön ki belle), tehát érthet, hogy az kevésbé befolyásolja az elzetes meggyzdésünket  ilyenkor még a poszteriort a prior dominálja. De ha nagyon hosszú a kísérletünk, akkor már perdönt ami abból kijön, kevéssé számít, hogy elzetesen hogyan vélekedtünk. A bayes-i módszertan tehát automatikusan megvalósítja ezt az átmenetet. Felmerül még a kérdés, hogy a bayes-i megközelítésbl mégis hogyan kapunk becslést, azaz egyetlen számot, mint amit tippelünk az ismeretlen értékre? Hiszen úgy tnik, hogy itt csak komplett eloszlásunk van! Valóban, valahogy a legvégén az eloszlásból egyetlen számot kell gyártani. Erre többféle módszer is van, itt most nem tárgyalom részletesen11, csak az érzékeltetés kedvéért: olyan megoldások lehetségesek, mint hogy vesszük azt az értéket, ahol a poszterior eloszlás maximuma van, vagy egyszeren vesszük az egész eloszlás várható értékét. És ezzel végeztünk! Felépítettük a becsléselméletet bayes-i alapokon is. A kérdés már csak egy: melyik a jobb? A maximum likelihood jelleg megközelítés, vagy a bayes-i? Ez a probléma a 20. század közepén, második felének az elején merült fel csak (noha a Bayes-tétel 200 évvel korábbi), de akkor viszont nagyon is intenzív formában: a bayes-i megközelítést a statisztikusok egy kisebb, de nagyon elszánt része képviselte, akik elég elsöpr elutasítással találkoztak a többiek részérl, aminek az eredménye egy párját ritkitóan harcias tudományos összeütközés lett a két iskola hívei között. Ebben a vitában nagyon sok részletkérdés van, de a legfontosabb probléma egyszer: a priorok ügye. Sok ember gyomra nagyon-nagyon(-nagyon-nagyon) nehezen veszi be, hogy ahhoz, hogy eredményt kapjunk, kell valamit mondanunk arról, hogy mit gondolunk még mieltt egyáltalán belefogunk a kísérletbe Hát én szeretnék csak a kísérlet alapján választ kapni! Pont azért csináltam a kísérletet, hogy megtudjam mi a helyzet! A bayes-i megközelítésben ezt nem lehet, és nem azért, mert nem vagyunk elég ügyesek, hanem mert ez elvileg lehetetlen, hiszen ebben a megközelítésben a kísérlet csak módosítja a hiedelmünket. Ez nem objektív!  mondják sokan. Hiszen az az objektív, ami magából a kísérletbl kijön, és pont, az alapján kell nyilatkozni, az egy teljesen megfoghatatlan szubjektív dolog, hogy én mit mondok mi volt az elzetes elképzelésem hát mondhatok akármit! És hogy ezen múljon a végeredmény?! Persze, másik oldalról ott van, hogy a bayes-i eljárás ad választ az igazi kérdésre. Nem a fordított valószínséget nézi, hanem azt, ami tényleg releváns számunkra. Ennek az ára az, hogy kell a prior. Ami az objektivitást illeti, a bayes-i módszer hívei erre azt mondják, hogy a maximum likelihood jelleg megközelítésben nincs kevesebb szubjektivitás, csak az el van rejtve különféle részletekben (például a mintavétel jellegének meghatározása), és akkor már jobb, ha ez explicite megjelenik. E helyütt természetesen nem fogok igazságot szolgáltatni ebben a kérdésben. Két feladatot érzek fontosnak, az egyik  ami a fentiekben megtörtént  bemutatni a bayes-i gondolkodást is mint egyenrangú alternatíva, mert ez sok irodalomban vagy nem jelenik meg, vagy csak a másik megközelítés nagyon részletes ismertetése után. Látni kell, hogy jelenleg a legtöbb statisztikai területen a másik iskola dominál, így bármit is gondolunk róla, a második feladat azt részletesen bemutatni, hiszen abban a szellemben íródott cikkeket kell túlnyomó többségben megérteni (és, ha úgy adódik, jellemzen írni is). 2.4 A frekventista statisztika építménye Az egyetlen mód, hogy érthetvé tegyük a frekventista eljárásokat az, ha hazudunk róluk. Frank Harrell Elször kezdjük gyorsan egy terminológiai kérdéssel: amit korábban többször is úgy hívtam, hogy maximum likelihood jelleg megközelítés, az hivatalos nevén a frekventista megközelítés. Ha valaki arra asszociál, hogy ilyenrl már volt szó, a valószínség interpretációi kapcsán (1.4. alfejezet), akkor hamar ki fog derülni, hogy ez egyáltalán nem véletlen. Ahogy a korábbiakból is kiderült, a frekventista hozzáállás legfontosabb komponense két szóban összefoglalható: fordított logika. Nem azt nézzük, hogy feltéve a mintát mit tudunk mondani valami ismeretlen dologról, hanem azt, hogy feltéve az ismeretlen dolgot, mit tudunk mondani a mintáról. Ez minden frekventista eljárás sajátja! Hogy ezt mélyebben megértsük, kapirgáljuk meg kicsit jobban a maximum likelihood becslt a pénzfeldobásos példában. Megbeszéltük, hogy ekkor az ismeretlen \\(p\\) paraméter, az érme ismeretlen fej-dobási valószínsége a kísérletben kapott fej-dobási aránnyal becsülhet maximum likelihood módon. Azt is megjegyeztük, hogy ez persze csak tipp, hiszen biztosak soha nem lehetünk. Nézzük meg az utóbbit kicsit közelebbrl! Mondjuk, hogy ismerjük a \\(p\\)-t (fordított logika!), és nézzük meg, hogy ekkor a mintabeli arány hogyan viselkedik! Például legyen a \\(p=0,\\!6\\), ekkor mekkora valószínséggel dobunk 10-bl 0 fejet, 10-bl 1-et, 10-bl 2, , 10-bl 10-et. A számítást már láttuk is a fejezet elején, csak most nem különböz \\(p\\)-kre számítjuk ugyanazt a fej-dobás számot, hanem ugyanarra a \\(p\\)-re különböz fej-dobás számokat. Íme az eredmény: Tehát még egyszer, ha \\(0,\\!6\\) az ismeretlen paraméter valódi értéke, így fog eloszlani, hogy mi mennyit becsülünk rá a mintából! Látszik, hogy ha pechünk van, akár nagyon eltérhetünk, becsülhetünk akár 20%-ot, vagy 100%-ot is  de ezeknek kicsi a valószínsége. De ami még fontosabb: meg tudjuk mondani, hogy mennyi! De egy pillanatra álljunk is meg itt rögtön. Mi az, hogy mekkora valószínséggel dobunk 2 vagy 10 (vagy akárhány) fejet? Itt van az asztalon a pénzérme, épp most dobtam vele 7-szer fejet, akkor meg mirl beszélek, hogy mekkora valószínséggel dobok 2-szer fejet?! Hát 0, mert 100% valószínséggel 7-et dobtam! Itt jön a frekventista iskola kulcsgondolata: a valószínségek csak úgy kapnak értelmet, ha képzeletben újra meg újra megismételnénk a kísérletünket! Felvenném a pénzérmét (ugyanazt! tehát \\(p\\) ugyanannyi!) és újra megcsinálnám a 10 dobásos kísérletet. Feljegyzem, hogy hány fej lett, majd megint megismétlem. Majd megint. Majd megint. Majd megint. Aztán amikor nagyon sokszor megtettem, akkor megszámolom hogy hogyan oszlik meg a fej-dobások száma  és így az elbbi ábrát kapom! Persze, hiszen a valószínség frekventista értelmezése az volt, hogy amihez a relatív gyakoriság tart, itt a relatív gyakoriság az, hogy az esetek mekkora részében kaptam mondjuk 2 fejet, amire az elbb azt mondtam, hogy megszámolom hogy hogyan oszlik meg a fej-dobások száma. De azt, hogy mihez tart a relatív gyakoriság, csak akkor tudom, ha elég sokszor megismételtem az egész 10 dobálásos kísérletemet. Tehát miközben egyetlen kísérletem van ténylegesen, ilyen értelemben beszélhetek csak valószínségrl. Képzeletbeli ismételt mintavétel  ez minden frekventista eljárás mentális modellje. Ez az az aspektus (a fordított logika hangsúlyozása mellett), amit gyakran elhanyagolnak, és csakugyan egyszerbbnek tnhet elmismásolni, hiszen kissé agyzsibbasztó dologról van szó, de késbb komoly félreértések táptalaja lehet, ha ezt nem értjük meg jól. Érdemes itt még egy terminológiát bevezetni. Ahogy már én is használtam, a kísérletünk kimenetét, amit megfigyelünk, mintának szokás nevezni, míg a mögötte képzeletben lév eloszlást, aminek valamilyen ismeretlen jellemzjére kíváncsiak vagyunk, sokaságnak. E szavak talán jobban érthetek ha arra az esetre gondolunk, amikor a sokaság nem egy eloszlás, hanem elemeivel adott. Ez fleg a társadalomtudományok terén fordul el: a sokaság mondjuk az elséves egyetemisták 1000 fs halmaza, és arra vagyunk kíváncsiak, hogy átlagosan mennyi idt fordítanak hetente tanulásra, de nem tudjuk mindegyiket megkérdezni, csak mondjuk  véletlenszeren kiválasztott  100-at közülük. Ekkor pontosan ugyanaz lesz a problémánk: mind az 1000 átlaga egyetlen adott, jól meghatározott érték  csak mi nem fogjuk tudni, hogy mennyi! Hiszen csak 100-at ismerünk, és az abból kiszámolt becslés, akárhogy is számolunk, attól is fog függeni, hogy pont melyik 100-at választjuk ki. (És itt most kizárólag a véletlen szeszélyérl beszélek, ezért is hangsúlyoztam, hogy véletlenül vettük a mintát.) Ha képzeletben újra meg újra eljátszanánk azt, hogy 100 ft véletlenszeren kiválasztunk, és kiszámoljuk belle a becslést, akkor ez mintáról mintára más lenne. A helyzet tehát teljesen analóg12, de itt talán jobban érthet, hogy miért mondunk mintavételt: a sokaság az, amire a kérdésünk irányul, de ezt az egész halmazt nem tudjuk megfigyelni (azaz lemérni); azt a részét, amit igen, hívjuk mintának. Ezért mondhatjuk a pénzfeldobásra is, hogy azzal mintát veszünk az ismeretlen sokaságból. Térjünk most vissza a frekventista következtet statisztika alapkérdéseire. A látott problémát, tehát, hogy hiába volt adott, állandó, rögzített értéke az ismeretlen paraméternek, mi mégis más és más becslést kapunk mintából, ha (képzeletben) újra meg újra mintát veszünk, szokás mintavételi ingadozásnak nevezni. A frekventista iskolában ez a kézenfekv elmagyarázása annak, hogy miért nem lehet soha biztos állítást tenni: hiába is adott érték \\(p\\), akkor is kaphatunk más értékeket a mintából. Ugyanaz volt a sokaság, ugyanúgy véletlen mintát vettünk, mégis mást és mást kaptunk. A fenti grafikont, amelyen látjuk, hogy az ismeretlen paraméter adott értékénél hogy oszlik el a mintából becsült paraméter (a mintavételi ingadozás miatt) szokás a becslfüggvény mintavételi eloszlásának nevezni. Érdemes kicsit kísérletezni, hogy ez hogyan függ a \\(p\\)-tl és  különösen  a mintanagyságtól: Némi játszadozás után levonhatjuk a legfontosabb tanulságot: minél nagyobb a mintaméret, annál kisebb a mintavételi ingadozás mértéke! Azaz, annál kisebb lesz a bizonytalansága a mintából becsült értéknek. Ez egy nagyon fontos megállapítás, hiszen azt eddig is láttuk, hogy a mintavételi ingadozás soha nem szüntethet meg (biztos állítást soha nem tudunk tenni), de most már látjuk, hogy mi az az egyetlen dolog, amit viszont tehetünk ellene: megnövelhetjük a mintanagyságot, ha ráadásul számszersíteni is tudjuk a mintanagyság és a mintavételi ingadozás közti összefüggést (és elárulhatom: tudjuk), akkor meg tudunk oldani olyan problémát, hogy ha megadják milyen biztos becslés kell, akkor meghatározzuk, hogy ahhoz mekkora mintaméret szükséges. Ezekkel a kérdésekkel azonban már kezdünk a következ fejezetünk témájára átkerülni: hogy a becslésben lév bizonytalanságot hogyan lehet megragadni, jellemezni. Felmerül a kérdés, hogy a likelihood-ot hogy mondják magyarul, a válasz: likelihood. A probléma az, hogy a valószínség-ként való lefordítás konkrétan hibás; próbálkoztak régebben a valószerség fordítással, de nem igazán ment át a gyakorlatba. Van más értelmezése is annak, hogy mit jelent a nem tudunk semmit, de ez félig (nem teljesen!) a filozófia tárgyköre. Ezt szokták egyenletes eloszlásnak hívni: bármely 0 és 1 közti intervallumba akkora valószínséggel esik, mintha az intervallum hossza. Ez tényleg azt jelenti, hogy bármely pont környékére ugyanakkora valószínséggel esik. Azért az okát elmondom: ahhoz, hogy megmondjuk, hogyan gyártunk az egész eloszlásból egyetlen számot, szükség van még egy döntésre: meg kell határoznunk, hogy adott tévedést, hogy a tippelt érték mennyire ment a valós mellé, milyen súlyosnak minsítjük. Például ha kétszer távolabb vagyunk a valóságtól, az kétszer nagyobb baj? Vagy négyszer? Vagy ugyanakkora baj, mert csak az számít, hogy nem találtuk el? Ha erre a kérdésre válaszolunk, akkor abból már kiadódik a becslfüggvény. Ez szó szerint igaz: az elemeivel adott sokaság is elmondható úgy, mintha egy eloszlás lenne a háttérben: egy diszkrét eloszlás, mely 1000 értéket vehet fel, melyek nem mások, mint az 1000 hallgató tanulással töltött óráinak száma, és mindegyiket \\(1/1000\\) valószínséggel veszi fel. A 100 hallgató véletlenszer kiválasztása tehát tényleg pontosan olyan, mintha ebbl az eloszlásból feldobnék 100 pénzérmét. "],["a-bizonytalanság-jellemzése.html", "3 . fejezet A bizonytalanság jellemzése 3.1 Intervallumbecslés 3.2 Hipotézisvizsgálat", " 3 . fejezet A bizonytalanság jellemzése Az elz fejezetben alaposan körüljártuk azt a megállapítást, hogy a következtet statisztikában nincs biztos válasz. Elkerülhetetlen módon minden válaszunkat bizonytalanság fogja terhelni. A következtet statisztika egyik legnagyobb ereje, hogy e bizonytalanság mértékét magát is képes lesz jellemezni  ebben a fejezetben ezzel a kérdéssel fogunk foglalkozni. 3.1 Intervallumbecslés TODO 3.2 Hipotézisvizsgálat TODO "],["egy-alapvet-kutatásmódszertani-kérdés.html", "4 . fejezet Egy alapvet kutatásmódszertani kérdés 4.1 Az orvosi megismerés alapkérdései 4.2 Az okozatiság nyomában 4.3 A confounding problémája 4.4 Zavaró változóktól a megzavart olvasókig 4.5 Egy aranyérmes megoldás 4.6 Megfigyelés és kísérlet 4.7 A jó, a rossz, és a közepesnél némileg gyengébben jó", " 4 . fejezet Egy alapvet kutatásmódszertani kérdés Statisztikával hazudni könny, de statisztika nélkül még könnyebb. Charles Frederick Mosteller A statisztika tulajdonképpen az elz fejezettel befejezdött. Nem tudom megállni azonban, hogy ne hívjam fel a figyelmet pár általános, mondjuk úgy: kutatásmódszertani kérdésre. Azért nem, mert ezek borzasztó gyakran épp a statisztikát alkalmazunk! felkiáltás ürügyén sikkandnak el. Soha nem szabad ugyanis egy dolgot elfelejteni: mindaz a statisztikai apparátus, amirl az elmúlt fejezetekben szó volt csak és kizárólag a mintavételi ingadozásból fakadó bizonytalanság kezelésére alkalmas, és a világon semmit nem mond egy kutatás összes többi hibaforrásáról! Ezért nagyon rossz, amikor valaki a következtet statisztika alkalmazásával kapott eredményeket, mondjuk a \\(p\\)-értékeket úgy kezeli, hogy akkor ezzel a kutatás hibáinak problémája le van tudva. A \\(p\\)-értékek nem egy kutatás hibázásának univerzális metrikái  simán elfordulhat, hogy egy kutatási domináns hibaforrását nem a mintavételi ingadozás jelenti! Éppen ezért fontos, hogy ismerjük ezek közül minimum a legfontosabb problémát, a confounding-ot, mely szinte minden társadalmi-gazdasági (és sok orvosi) vizsgálatban felmerül. Amíg ezt nem tisztáztuk egy vizsgálat kapcsán, addig tizedrangú kérdés, hogy a kapott eredmény a szó statisztikai értelmében szignifikáns-e. A most következ leírásom orvosi példákat fog hozni13, de reményeim szerint közvetlenül látszódni fog, hogy ugyanez a kérdéskör hogyan jelenik meg más területeken is. 4.1 Az orvosi megismerés alapkérdései Egy friss újsághír szerint egy svéd egyetem kutatói félmillió gyermek környezetét vizsgálták meg, és azt találták, hogy ahol magasabb a légszennyezettség, ott több a mentálisan beteg gyermek. A légszennyezés tehát mentális betegséget okoz! Vagy mégsem? Az orvostudomány egy jelents része ilyen, és ehhez hasonló kérdésekre igyekszik választ adni: okoz-e mentális betegséget a légszennyezés? A mobiltelefon-használat agyrákot? A vöröshús-fogyasztás vastagbélrákot? A császármetszéssel születés megnöveli-e annak kockázatát, hogy a gyermeknek késbb 1-es típusú cukorbetegsége lesz? És ha az anya paracetamolt szed a terhesség alatt, attól lehet a gyermek autista? Itt van ez az új vérnyomás-csökkent gyógyszerjelölt, vajon csökkenti-e tényleg a vérnyomást? És okozhat-e alvászavart mellékhatásként? E kérdésekre számos módszerrel kereshetjük a választ. Alapul vehetünk biológiai (élettani, kórélettani) megfontolásokat, kereshetünk állatmodelleket, amik lehetvé teszik a jelenségek vizsgálatát, tekinthetünk analóg példákat más területrl, gyárthatunk matematikai modellt, azonban a jelen cikksorozat tárgya egy más jelleg, ám egyre fontosabb módszer: az empirikus vizsgálat. Az empirikus annyit tesz: tapasztalati, úgyhogy rögtön pontosítanom kell: a legrosszabb orvosi megismerési módszerek is tapasztalatokon alapulnak, ezért talán jobb, ha úgy mondjuk: szisztematikus empirikus vizsgálat. Empirikus, mert az alapján próbáljuk megválaszolni a kérdést, hogy begyjtünk tényadatokat gyermekek környezetének légszennyezettségérl és a tényleges megbetegedéseikrl, és szisztematikus, mert ezt nem ötletszeren, hanem valamilyen terv szerint tesszük. A kérdés tehát adott: miután megvannak ezek az adatok, hogyan következtethetünk azokból arra, hogy okoz-e mentális betegséget a légszennyezés? Els ránézésre könny dolgunk van: empirikusan dolgozunk ugyebár, ezért begyjtünk tényadatokat gyermekek lakóhelyének légszennyezettségérl, és esetleges késbbi megbetegedéseikrl. Szisztematikusan dolgozunk, ezért a mintavételt alkalmas terv szerint végezzük, például a népességnyilvántartó adataiból teljesen véletlenszeren választunk ki kellen sok gyermeket. (Tehát véletlenül sem internetes kérdívet küldünk ki, többek között a Megbetegítették a gyermekemet a légszennyezettséggel!!! Facebook-csoport tagjainak, megkérve, hogy idézzenek fel az összefüggést megersít illetve cáfoló példákat.) A kapott eredmények, a példa kedvéért: a 100 ezer nem légszennyezett helyen él gyermek közül 1310-nél lépett fel mentális betegség, a 100 ezer légszennyezett környezetben felnöv közül azonban 3750-ben. A különbség drámai. Márpedig szisztematikusan dolgoztunk, a lehet legjobban: véletlenszeren választott adatokkal, empirikusan vizsgáltuk a kérdést, ráadásul igen nagy mintán, úgyhogy hátradlhetünk és nagy nyugalommal mondhatjuk: a légszennyezettség mentális betegséget okoz! Vagy mégsem? 4.2 Az okozatiság nyomában A válaszhoz induljunk egy picit távolabbról. Érdemes felidézni az elz alfejezetbl, hogy milyen szerteágazóak azok a  fentihez hasonló  kérdések, melyekre választ szeretnénk adni az orvostudományban: Okoz-e agyrákot a mobiltelefon használata? A vörös hús fogyasztása vastagbélrákot? A császármetszéssel születés megnöveli-e annak kockázatát, hogy a gyermeknek késbb 1-es típusú cukorbetegsége lesz? És lehet-e a gyermek autista attól, hogy az anya paracetamolt szed a terhesség alatt? Itt van ez az új vérnyomáscsökkent gyógyszerjelölt, vajon tényleg csökkenti-e a vérnyomást? Okozhat-e alvászavart mellékhatásként? Ebben a listában igyekeztem, teljesen szándékosan, a lehet legkülönbözbb kérdéseket összegyjteni, melyekben látszólag egyetlen közös pont sincs. Ezt azért tettem, hogy még meglepbb legyen a következ kijelentésem: azt állítom ugyanis, hogy bármennyire is különböznek tnnek, valójában kivétel nélkül az összes felsorolt kérdés mögött  és milliónyi egyéb orvosi, egészségügyi kérdés mögött  pontosan ugyanaz a séma van! Persze, a konkrét részletek nagyon eltérnek, de ha ezektl megtisztítjuk az egyes kérdéseket, akkor a mélyben minden esetben ugyanazt találjuk. Az egyik komponens: minden kérdésben található valami, amit teljesen általános szóval expozíciónak fogunk hívni. Ez szó szerint kitettséget jelent, és tényleg azt is értjük alatta, hogy az alany ki volt téve valamilyen hatásnak. Ezt a legáltalánosabban értjük: a hatás lehet valami, amit szándékosan alkalmazunk az alanyon (pl. gyógyszert adunk neki), lehet valami, amit maga választ (pl. vörös húst fogyaszt), és olyasvalami is, aminek akaratán kívül van kitéve (pl. császármetszéssel született). Érdemes végignézni az összes elbbi példát, csakugyan mindegyikben azonosítható az expozíció, a mobiltelefon-használattól egészen a gyógyszerszedésig. A másik komponens: minden kérdésben található valamiféle eredmény, kimenet  ezt fogjuk végpontnak hívni. Ez lesz az orvosilag lényeges, általunk vizsgált történés; ismét csak, érdemes egy pillanatra visszanézni az elbbi listára, és mindegyik elemnél megkeresni ezt, az agyráktól az alvászavarig. Ezzel megvan a séma két oldala, expozíció egyfell, végpont másfell, már csak egyetlen komponens hiányzik, amit vizsgálni akarunk minden ilyen és ezekhez hasonló kérdésben: az, hogy az expozíció és a végpont között van-e ok-okozati összefüggés. Szép szóval ezt hívhatjuk kauzalitásnak. Bármennyire is különböznek tnnek a kérdések, e séma mindegyikre illeszkedik, mindegyikben azonosítható az expozíció, azonosítható a végpont, és mindegyikre igaz, hogy okozatiságot kutatunk. De mit is jelent ez a fogalom? Kézenfekv értelmezés, hogy megnézzük, hogy hány beteg volt a légszennyezéses csoportban, megnézzük, hogy hány lett volna köztük, ha minden más változatlan lett volna, de nem lett volna légszennyezés  és a kett különbség a légszennyezés hatása. Sajnos ezt a másodikat soha nem ismerhetjük, hiszen ez egy valójában létre nem jött, képzeletbeli helyzet. Éppen ezért jobb híján a nem légszennyezéses csoporthoz viszonyítunk, tehát nem ugyanazon csoport tényleges és képzeletbeli helyzetét vizsgáljuk, hanem két különböz csoport tényleges helyzetét viszonyítjuk egymáshoz. Lényegében azt mondjuk, hogy a nem légszennyezett környezetben felnöv gyermekek adatai mutatják, hogy mi lett volna, ha a légszennyezett környezetben felnövknél nem lett volna légszennyezés. Csakhogy ez egy nagyon ers feltevés: kizárólag akkor igaz, ha a két csoport semmi másban nem tér el, egyedül a légszennyezettség tényében. A tételmondatot mindenesetre megfogalmazhatjuk: Az expozíció akkor van okozati összefüggésben a végponttal, ha a csak az expozícióban eltér csoportok eltérnek a végpontban, mégpedig olyan mértékben, ami már nem tudható be a véletlen ingadozásnak. Ez utóbbi az, amit már tudunk kezelni a következtet statisztika apparátusával! Csakhogy a mondat els felében is komoly csapdák vannak elrejtve 4.3 A confounding problémája Ebben a tételmondatban tehát van egyetlen egy szó, ami iszonyatos bonyodalmakat okoz: az, hogy csak. Biztos, hogy az összehasonlított csoportjaink kizárólag csak az összehasonlítás tárgyában, tehát az expozícióban térnek el? Biztos, hogy a légszennyezett területen felnöv és az egészséges levegben felnöv gyermekek között csak és kizárólag az a különbség, hogy milyen a levegminség a lakhelyükön? Dehogy! A nagyobb légszennyezettség területek nagyon gyakran épp a városok peremkerületeit jelentik, az ipari negyedeket, az elavult ftés, leszakadt részeket. Itt azonban tendenciájában inkább rossz körülmények között él, kevésbé tehets családba született (egyszóval: rosszabb szocioökonómiai helyzet) gyermekek fognak lakni. Igen ám, de a rosszabb szocioökonomiai helyzet egy sor betegség magasabb kockázatát hordozza - mi van, ha a mentális betegségek is ezek közé tartoznak? Mert a rosszabb szocioökonómiai szegmensben a várandósok kevésbé férnek hozzá a szülés eltti gondozáshoz, közülük több dohányzik vagy fogyaszt alkoholt a várandósság alatt. A gyermekekre sem csak a rosszabb leveg hat, hanem a rosszabb táplálkozás, hogy kevésbé vesznek részt szréseken és így tovább, és így tovább. Innentl kezdve, ha találunk is különbséget a mentális megbetegedések elfordulásában a két csoport között, nem tudhatjuk, hogy az minek a következménye: az általunk vizsgált levegminségbeli eltérésnek, az ezzel  óhatatlanul!  együttjáró egyéb eltéréseknek, vagy esetleg ezek keverékének?! Ezt nem tudhatjuk  hiszen az összehasonlított csoportok nem csak az összehasonlítás szempontjában tértek el. A problémát tehát az jelenti, hogy a két változó kapcsolatát megzavarja egy harmadik változó, mely egyszerre hat az expozícióra és a végpontra. Ez a naiv elképzelés: És ez a valódi helyzet: Ennek következtében elképzelhet, hogy a légszennyezettségnek valójában nincs is a világon semmilyen hatása a mentális betegségekre, amit látunk, az egy látszólagos hatás, annak következtében, hogy a légszennyezett területen felnöv gyermekek körében egész egyszeren több a rossz szocioökonomiai helyzet, ami pedig a valódi oka a több mentális betegségnek! Ha valaki nem hiszi el, hogy ilyen létezhet, akkor nézze meg képzeletbeli adatgyjtésünk részletesebb eredményeit, melyet a következ táblázat mutat: Légszennyezett Nem légszennyezett Összesen Rossz szocioökonómiai helyzet 6% (3300/55000) 6% (375/6250) 6% (3675/61250) Jó szocioökonómiai helyzet 1% (450/45000) 1% (935/93750) 1% (1385/138750) Összesen 3,8% (3750/100000) 1,3% (1310/100000) 2,5% (5060/200000) Ebben a táblázatban valami els ránézésre egészen paradox dolog látható. (Azért írtam oda nem csak a százalékokat, de a számokat is, mert néhányan azt szokták mondani, hogy ez matematikailag is lehetetlen. Errl szó nincs, ha valaki nem hiszi, adja össze és ossza el a feltüntetett számokat!) Mert mit látunk? Azt, hogy a rossz szocioökonómiai helyzet gyermekek körében nincs hatása a légszennyezésnek (így is, úgy is 6% az elfordulása), a jó szocioökonómiai helyzet gyermekek körében szintén nincs hatása (1% így is, úgy is)  összességében viszont mégis van! Hiszen az 1,3% megntt 3,8%-ra, ahogy azt a felvezetben is írt számok mutatják. Ez meg hogy a csudában lehet?  kérdezhetné valaki. Se egyik csoportban nincs hatása, se a másikban, de összességében mégis van?! Rakjuk most össze, hogy mi is történt itt. A problémát az okozta, hogy volt egy változónk, mely egyszerre tudott két dolgot: egyrészt összefüggött az expozícióval (nézzük meg, a jó szocioökonómiai helyzeteknek csak harmada élt légszennyezett területen, a rosszaknak majdnem 90%-a), másrészt befolyásolta a végpontot a légszennyezettségtl függetlenül, önmagában is (az 1%-os elfordulást 6%-ra emelte). Az ilyen változókat szokás zavaró változónak, vagy  magyarul is gyakrabban használt angol kifejezéssel  confoundernek nevezni; a jelenségnek magának pedig confounding a neve. (Ez egy nagyon találó angol kifejezés, amire sajnos nem honosodott meg hasonlóan frappáns magyar elnevezés. A confounding ugyanis szó szerint azt jelenti, hogy egybemosódás: a probléma valóban az, hogy az általunk vizsgált eltérés egybe van mosódva egy vagy több egyéb eltéréssel.) Ez az oka annak, hogy a naiv módszer (több-e a mentálisan beteg a magasabb légszennyezettség területeken?) csábító mivolta ellenére is teljesen fals! Hiába is dolgoztunk empirikusan, és hiába is gyjtöttünk szisztematikusan adatokat. Fontos felhívni rá a figyelmet, hogy a teljesen fals természetesen nem azt jelenti, hogy az eredményünk akkor valójában azt jelenti, hogy nem okoz mentális betegséget a légszennyezettség  természetesen okozhat, csak ez nem következik abból, hogy több a mentálisan beteg a szennyezettebb levegj területeken! Önmagában ez az együttjárás nagyon kevéssé bizonyítja az okozati összefüggést. Azt mondhatjuk, hogy nagyobb légszennyezettség együtt jár a több mentális betegséggel, de hogy a nagyobb légszennyezettség okoz-e több mentális betegséget, az egy sokkal-sokkal fogósabb kérdés, aminek kapcsán, mint a fentiek is mutatják, roppant óvatosan kell eljárni. Ez az ilyen jelleg adatok értékelésének egyik legnagyobb problémája (mely a laikus sajtóban is lépten-nyomon visszaköszön). A valóságban ráadásul messze nem olyan egyszer a helyzet, mint a fenti táblázatban, ahol van egy szem confounderünk. A valós helyzetek általában ennél sokkal-sokkal kuszábbak. Ennek illusztrálására vegyünk egy másik példát a cikk elejének listájáról: a császármetszéssel születés megnöveli-e az 1-es típusú cukorbetegség kockázatát? A császármetszéssel születk között több az 1-es típusú cukorbeteg, de  most már tudjuk  ez nem sokat jelent, hiszen mi van, ha vannak egyéb eltérések is a csoportok között? Ez csakugyan így van: a következ ábra mutatja, immár egy valós orvosi példán, a legfontosabb confoundereket ebben az esetben. Még itt se mondhatjuk persze, hogy ez az összes, de ez már valóságközelibb. Példának okáért, az anyai diabetes és a császármetszés közötti nyílon pozitív jel van, mert a cukorbeteg anyáknak általában nagyobbak a magzataik, és ez a különféle téraránytalanságok miatt gyakrabban vezet császármetszéshez. Másrészt a cukorbetegségnek van egy ers genetikai komponense, így az anyai cukorbetegségbl a gyermekéhez is pozitív nyíl vezet. És már ennyi is elég, hogy bajban legyünk: innentl kezdve, még ha azt is találjuk, hogy a császármetszéssel születettek körében több lesz késbb cukorbeteg (egyébként tényleg ez a helyzet), akkor sem tudhatjuk, hogy mi a valódi ok: csakugyan a császármetszés, vagy egyszeren csak az, hogy a császármetszéssel születknek gyakrabban cukorbeteg az édesanyja? És ez még csak az els confounder volt! Érdemes megnézni a másodikat, az anyatejes táplálást is. Ez rámutat arra, hogy az expozíció és a confounder között nem érdekes, hogy milyen az okozati kapcsolat iránya (az eddigi példákkal szemben itt most aligha arról van szó, hogy az anyatejes táplálás befolyásolja, hogy korábban császármetszés történt-e), csak az fontos, hogy kapcsolat van. És csakugyan, a császármetszéssel szül nk ritkábban táplálják anyatejjel a gyermeküket, ez így van a valóságban, és most az mindegy is, hogy ennek mi az oka. Másrészt az anyatejes táplálás (számos egyéb elnye mellett) csökkenti a cukorbetegség kockázatát is  és akkor e ponton megint meg vagyunk lve és még közel nem vagyunk a sor végén. 4.4 Zavaró változóktól a megzavart olvasókig Nem véletlenül írtam korábban, hogy a naiv módszer nagyon csábító tud lenni. Képzeljük csak el, pláne némi marketinggel meghintve: látványos grafikon, rajta a nem légszennyezett területen felnövk körében a kockázat (kicsi oszlop), mellett a légszennyezett területek adata (oszlop kiüti az oldal tetejét), szomorú anyuka megrázó beszámolója mentálisan beteg gyermekérl, természetesen hangsúlyozva a levegminséget stb. stb. Vajon 100 emberbl hánnyal hitetné el a légszennyezettség szerepét? (És hányan mondanák azt, hogy hohó, de hát itt óvatosnak kell lenni, mert a szocioökonómiai státuszon keresztül megvalósuló confounding van!?) Ha jobban megnézzük, mindennapi egészségügyi megállapításainkat lépten-nyomon átszövi ez a probléma. Nézzük meg kedvenc internetes portálunk egészségügyi rovatát is A több zöldséget fogyasztók 10 évvel tovább élnek! Biztos, hogy a több zöldséget fogyasztók csak a zöldségfogyasztás mértékében térnek el a kevesebb zöldséget fogyasztóktól? Fogadjuk el, hogy igaz az állítás, és tényleg együtt jár a több zöldségfogyasztás a hosszabb élettartammal. Akkor végül is igaz ez a mondat, minek rajta kötözködni?  kérdezhetné valaki. Szó nincs errl, ez nem akadékoskodás, éppen ellenkezleg, ez a legfontosabb kérdés. A mondat nyilván azt akarja sugallani, hogy együnk több zöldséget, hogy tovább éljünk. De ha valójában az elz nem okozati kapcsolat, csak együttjárás, akkor  mivel a valódi ok más volt  ezzel nem megyünk semmire! Márpedig számunkra ez a fontos: ha egy ilyen cikket olvasva életünket úgy változtatjuk meg, hogy növeljük a zöldségfogyasztásunkat, akkor várhatjuk-e ettl, hogy megn az élettartamunk? A sor ugyanerre a mintára sajnos igen hosszan folytatható. Az indiai konyha rengeteg curry-t használ, és lám, velünk szemben ott szinte ismeretlenek a gyulladásos bélbetegségek! (Biztos, hogy India és Magyarország között csak és kizárólag az az egyetlen különbség, hogy a fzéshez más mennyiség curry-t használunk?) Azokban az amerikai államokban, ahol többet alszanak, kevesebb a depressziós! (Biztos, hogy ezen amerikai államok csak és kizárólag az alvással töltött órák számában térnek el a többitl?) A legszebb, amikor ugyanazt eljátsszuk oda és vissza is: 30 éve még nem használták ilyen széles körben a vérnyomás-csökkentket, és jóval több is volt a magas vérnyomásos beteg! (Biztos, hogy 2018 és 1988 között az egyetlen különbség a vérnyomás-csökkentk használatának a mértéke?) 30 éve még nem használták ilyen széles körben a védoltásokat, és jóval kevesebb is volt az autista! (Biztos, hogy 2018 és 1988 között az egyetlen különbség a védoltások használatának a mértéke?) 4.5 Egy aranyérmes megoldás Mit tudunk tenni a confounding problémája ellen? Törekedni sokféleképp lehet arra, hogy a csoportok csak a vizsgált tényezben térjenek el, de biztosan elérni csak egyféleképp. Tulajdonképpen az a meglep, hogy a megoldás milyen késn merült fel. 1931-ben a michigan-i William H. Maybury Tüdszanatórium orvosa, James Burns Amberson ki akarta deríteni, mégpedig empirikusan, hogy egy sanocrysin nev szervetlen aranyvegyület vajon gyógyítja-e a TBC-t (elég sok írás született ennek lehetségérl akkoriban). Az  ugyebár!  nem jó megoldás, hogy összehasonlítjuk a gyógyszert kapó és gyógyszert nem kapó betegek gyógyulását, hiszen mi van, ha k másban is eltérnek a gyógyszerben részesülés tényén túl? Mi van, ha a gyógyszert inkább kapták a fiatalok (vagy pont, hogy az idsek), inkább kapták a férfiak vagy a nk, inkább kapták a több vagy kevesebb társbetegséggel rendelkezk stb. Ez jelen esetben a legkevésbé sem elméleti spekuláció, nagyon is könnyen lehet, hogy egy új, még nem jól ismert kezelést inkább a jobb állapotú és így egyúttal legjobb gyógyhajlamú betegeknek írnak fel inkább az orvosok. Tehát a gyógyszert kapó és nem kapó csoportok ilyen összehasonlítása teljesen félrevezet lehet  belefutottunk a confounding problémájába. Amberson és munkatársai egy huszárvágással megoldották a problémát: pénzfeldobással döntötték el, hogy ki kapjon sanocrysin-t! És ezt most nem irodalmi fordulatként mondom, hanem a szó szoros értelmében: Amberson konkrétan feldobott egy pénzérmét és az alapján adott sanocrysin-t vagy egyszer desztillált vizet a betegeknek, hogy fejet vagy írást kapott, ezt pontosan dokumentálta is a cikkében. Még arról is gondoskodott, hogy a két szer külsleg ne legyen megkülönböztethet, és, hogy a dobás eredményérl ne tudjon a beteg, csak két orvos és a beadó nvér. És ennyi. Ezzel, a történelemben elször, megoldódott a confounding problémája. Majd látni fogjuk, hogy az ismert confounderek kiszrésére lesz módunk: ha eszünkbe jut, hogy a gyógyszert inkább fiatalabbak, vagy inkább férfiak kapják, és ezért feljegyezzük nem csak gyógyszerben részesülés tényét, hanem azt is, hogy az alany milyen ids és mi a neme, akkor ezeket  mint zavaró tényezket  ki fogjuk tudni szrni. De ennek minimális feltétele, hogy eszünkbe jusson, hogy mik a confounderek, és le is tudjuk ket mérni (egy olyannál, mint a szocioökonómiai státusz ez utóbbi sem nyilvánvaló). Amberson megoldásában, amit az orvosi irodalomban randomizációnak szokás nevezni, az a zseniális, hogy minden confoundert kiszr, azokat is, amiket nem tudunk feljegyezni, st, azokat is, amik eszünkbe sem jutnak! Tegyük fel például, hogy kiderül, hogy a kékszemeknek az orvosok inkább adnak sanocrysin-t és a kék szem egyúttal növeli a TBC-bl való gyógyhajlamot. Ez csúnyán tönkretenné az összes vizsgálatot, hiszen ki gondolna arra, hogy a szemszínt is fel kell jegyezni, de vegyük észre, hogy  mert ez a lényeg  Amberson módszere még ekkor is mködik! Hiszen a pénzfeldobás révén a kékszemek arányában sem lesz szisztematikus különbség a két csoport között! Ugyanúgy, mint ahogy nem lesz szisztematikus különbség a nemi összetételben, az életkori összetételben, és egyáltalán: semmilyen szempontban sem! Úgy is mondhatjuk, hogy a randomizáció kiszri, ráadásul automatikusan kiszri mind a végtelen számú potenciális confoundert  azokat is, amiket nem tudtunk feljegyezni, st, azokat is, amikrl eszünkbe sem jut, hogy confounderek! Ez a randomizált kutatások hihetetlen nagy elnye. (Ez a kiszrés természetesen nem azt jelenti, hogy biztosan minden szempont tökéletesen kiegyensúlyozott lesz a csoportok között. A pénzfeldobás szeszélye folytán elfordulhat, hogy puszta véletlenségbl több kékszem lesz az egyik csoportban, de be lehet látni, hogy mivel ez csak a véletlen szeszélye folytán állt el, így nem befolyásolja a fenti állításokat.) 4.6 Megfigyelés és kísérlet Amberson módszerének egy roppant fontos jellemzje van: befolyásolnunk kell hozzá, hogy ki kap gyógyszert (expozíciót). Azokat az orvosi vizsgálatokat, ahol a kutatók aktívan befolyásolják az expozíciót, kísérletes vizsgálatnak, azokat, ahol csak passzívan feljegyzik, hogy mi történt, de nem befolyásolják azt, megfigyeléses vizsgálatnak szokás nevezni. A kísérletek története messzire nyúlik vissza, ám a korai kísérletek problémája az, hogy mindig ott van a lehetség, hogy az orvos, akár teljesen tudattalanul is, de célirányosan befolyásolja, hogy ki melyik csoportba kerül. Ezt már a XIX. század végére felismerték, ezért akkorra divatba jöttek az úgynevezett váltakozó besorolású kutatások, ami azt jelentette, hogy minden második beteg kapta meg a vizsgált gyógyszert, minden második nem. Ez már egészen közel van a randomizált vizsgálatokhoz (az csak nem befolyásolja a gyógyulásomat, hogy páratlan sorszámú beteg voltam-e aznap a kórházban!), de valójában még itt is jelentkezhet az elbbi probléma: sokszor leírták például, hogy az orvosoknak megesett a szíve egy betegen, ezért igyekeztek úgy rendezni az ellátást, hogy a kezelt csoportba kerülhessen. Ez nyilvánvalóan elrontotta a dolgot, ha mondjuk a legrosszabb állapotú betegeknél került erre a leggyakrabban sor. Éppen ezért a váltakozó besorolás helyét a XX. század közepe felé átvette a randomizált besorolás, különösen, hogy a híres statisztikus Ronald Fisher ennek az elméletét is kidolgozta (egyébként már Amberson orvosi alkalmazása eltt). Látható tehát, hogy a kísérletes vizsgálatok hihetetlenül nagy és roppant fontos elnye, hogy elvileg mentesek tudnak lenni a confoundingtól. (Gyakorlatilag persze nem feltétlenül: kísérletet is lehet rosszul csinálni.) A megfigyeléses vizsgálatoknál viszont, bármennyire is óvatosan járunk el, mindig a fejünk fölött fog Damoklész kardjaként lebegni a confounding: biztos, hogy minden tényez, amiben az összehasonlított csoportok eltérnek  az összehasonlítás tárgyán kívül  eszünkbe jutott? Biztos, hogy mindegyiket le tudjuk mérni? Biztos, hogy mindegyiket jól ki tudjuk szrni? Mindezeket látva adja magát a kérdés: akkor miért nem csinálunk mindig kísérletet? Erre a kérdésre vannak nyilvánvaló és kevésbé nyilvánvaló válaszok. A legnyilvánvalóbb, hogy bizonyos helyzetekben egyszeren lehetetlen: valószínleg apróbb nehézségeink támadnának a kutatásetikai bizottság eltt egy olyan kutatási tervvel, amelyben szülnket randomizáltan akarunk császármetszetni  függetlenül attól, hogy szükségük van-e rá  azért, hogy kiderítsük, hogy a császármetszés okoz-e cukorbetegséget (pedig, módszertani szempontból ez lenne a legjobb!). Hasonlóan nehéz embereket randomizáltan légszennyezett és kevésbé légszennyezett területen lakatni, csak hogy visszatérjünk az eredeti példánkra. Ilyen esetekben mindenképp maradnak a megfigyeléses vizsgálatok, azok minden bajával együtt is. Az érdekes az, hogy néha akkor is csinálunk megfigyeléses vizsgálatot, ha lehetne kísérletet is (vagy akár ténylegesen végeztek is kísérlet). Ez is mutatja, hogy a kísérleteknek más hátrányaik is vannak, túl azon, hogy drágák, id- és szervezésigényesek. Az egyik probléma, hogy a kísérletekben, épp az említett szervezésigény miatt, korlátozott a bevonható betegek köre. A néhány ezer fs kísérlet a legtöbb területen már nagynak számít, a néhány tízezer f pedig már nagyon nagynak, egy ennél is nagyobb kísérletet pedig csak extrém nehezen lehet megszervezni. (Ebbl adódóan nagyon kevés ilyenre van példa. Az utóbbi idk legnagyobb orvosi kísérlete, melyben minden egyes alany egyénileg randomizálásra került, a CAPITA kutatás volt, melyben azt vizsgálták, hogy egy pneumococcus elleni oltás tényleg csökkenti-e a pneumococcus okozta tüdgyulladások elfordulását 65 év felett. Elképeszt számú alanyt, 85 ezer ft vontak be, ehhez két év és 101 központ kellett, megszámlálhatatlan közremködvel; sejthetleg százmillió dolláros nagyságrendbe került ez az egyetlen kísérlet.) Hogy ez miért fontos? Azért, mert a nem elegenden nagy mintanagyság korlátozza, hogy milyen nagyságú hatást tudunk észrevenni, legyen szó akár kívánt hatásról, akár mellékhatásról, ha például egy gyógyszerrl beszélünk. Ha kicsi a mintanagyság, akkor egy kis javulást, vagy egy ritkán jelentkez mellékhatást nincs sok esélyünk észrevenni. Pontosan az elbbi a magyarázat a CAPITA esetére is: a pneumococcus okozta tüdgyulladás nem fordul el srn, így az oltás, legyen bármilyen hatásos is, darabra csak kevéssel tudja csökkenteni a tüdgyulladások számát. És csakugyan: még a 85 ezer alany is csak arra volt elég, hogy összesen kevesebb, mint 200  a vizsgálat szempontjából fontos típusú  tüdgyulladás elforduljon. De ugyanez a helyzet a mellékhatások terén is: ha egy mellékhatás csak minden 10 ezredik embert érinti, akkor minden matematikai indoklás nélkül is érezhet, hogy egy 5 ezer fs kutatásban esélyünk sem lesz észrevenni (pedig ez egyáltalán nem kis kísérlet!). Megfigyeléses vizsgálatokkal ezzel szemben összehasonlíthatatlanul könnyebben elérhet ilyen, vagy akár ennél is nagyobb mintanagyság. Gondoljunk arra, hogy a megfigyeléses vizsgálat sok esetben úgy néz ki, hogy adatbázisokból kérdezünk le alanyainkra vonatkozó információkat  itt a kutatás tehát nem azt jelenti, hogy fizikailag alanyokat kell kezelnünk, hanem azt, hogy a számítógép eltt ücsörögve lekérdezéseket kell írogatnunk. A kett bonyolultságát egy napon nem lehet említeni! Én magam is  harmincéves adjunktusként, 2 kutatótársammal  részt vettem olyan vizsgálatban, melyben néhány hónap alatt, és nulla finanszírozással, 400 ezer magyar beteg adatait dolgoztuk fel  a CAPITA esetében kutatók és segéderk ezreire és évekre volt szükség, meg mellesleg annyi pénzre, mint a Semmelweis Egyetem éves költségvetése, hogy 85 ezer alanyt össze tudjanak szedni A másik, elbbihez hasonló gyöker probléma a kísérletekkel, hogy abban is korlátozottak, hogy mennyi ideig lehetséges az alanyok utánkövetése. A gyakorlatban néhány hónap vagy legfeljebb néhány év érhet el (de az alanyok kihullása a vizsgálatból  nem megy el a következ vizitre, mert elfelejti, elköltözik, elveszti az érdekldését stb.  már ekkor is általában igen nagy probléma). Ennél hosszabb kísérlet lényegében kivitelezhetetlen, vagy csak a legelemibb adatok (például: életben van-e egyáltalán még az alany) gyjthetek be. Világos, hogy ez miért gond: amíg a kevés alany azt limitálja, hogy milyen nagyságú hatást tudunk észrevenni, addig a rövid utánkövetés azt korlátozza be, hogy mennyi id alatt kialakuló hatást  legyen az akár kívánt hatás, akár mellékhatás  tudunk észrevenni. Szinte esélytelen, példának okáért, kísérlettel eldönteni, hogy egy gyerekkori táplálkozási szokás vagy orvosi beavatkozás okozhat-e egy tipikusan idskorban, vagy akár felnttkorban jelentkez betegséget. De itt is elmondható: megfigyeléses vizsgálatokkal nem feltétlenül reménytelen a helyzet, hiszen adatbázisokból sokszor akár több évtizedes átfogású adatok is könnyen kigyjthetek. A harmadik lehetséges probléma a kísérletekkel, hogy a kísérletben részt vev alanyok  még a legjóhiszembb tervezés esetén is  szükségképp egy elég speciális, steril populációt jelentenek, már pusztán abból is adódóan, hogy hogyan verbuválják ezeket az alanyokat. Ez mindig felveti azt a kérdést, hogy találjunk bármit is a kísérlet alanyai körében, az vajon mennyire vonatkoztatható az összes alanyra? Megfigyeléses vizsgálatoknál ez a probléma sokkal kevésbé jelentkezik: gyakran akár az összes alany is bevonható a vizsgálatba, így aztán egész biztos nincs probléma az összes alanyra vonatkoztatással. 4.7 A jó, a rossz, és a közepesnél némileg gyengébben jó Összességében véve tehát a legfontosabb megállapítás, hogy nem lehet olyat mondani, hogy a kísérlet és a megfigyelés közül az egyik jó, a másik meg rossz. Mindkettnek jellemz elnyei és hátrányai vannak, így az, hogy melyik a szerencsés választás, mindig a konkrét kérdéstl függ: van ahol az egyik, van ahol a másik, a kérdés az, hogy az adott problémának mik a jellemzi. Az elbbi pontban mondottakat szem eltt tartva nagy vonalakban már mi is tudunk választani! A nincs jó meg rossz a fentinél általánosabban is igaz. Minden kutatásnak vannak hibaforrásai. Ilyen a confounding és ilyen a véletlen ingadozás is. Bizonyos kutatásokban több hibaforrás van, vagy komolyabb súlyúak vannak, másokban kevesebb. Van egy szó, amit nagyon szeretek erre: a bizonyítóer. Kifejezi, hogy a tanulmányok  ilyen értelemben vett  értéke nem bináris, mint azt néhányan hajlamosak gondolni: nagyon ritkán van olyan, hogy egy kutatás tökéletes (és így ami abban olvasható, az úgy van és pont) vagy, hogy teljesen hasznavehetetlen (ezért bármi is olvasható benne, semmit nem jelent). A valóságban ez egy folytonos skála: arról, hogy a szennyezettebb területeken több mentálisan beteg gyermek él sem mondható, hogy semmit sem jelent (a confounding miatt)  csak épp borzasztóan alacsony a bizonyítóereje (arra nézve, hogy a légszennyezettség mentális betegséget okoz). Valójában tehát nincs éles határvonal kísérletes és megfigyeléses bizonyíték között; minden kutatást a saját erényei és korlátai alapján kell értékelni. Ezt legékesebben az bizonyítja, hogy a különböz bizonyítékok egy ligában játszanak, már olyan értelemben, hogy lehet, hogy az általánosságban gyengébbnek tekintett bizonyítékok  például megfigyeléses vizsgálatok  képesek lehetnek kiváltani a kísérletes bizonyítékokat. Kipróbálta-e bárki, hogy vakbélgyulladásban a vakbélmtét hatásos beavatkozás a semmittevéshez képest? Meglepdnék Pedig borzasztó egyszer volna! Csak fogni kellene 200 vakbélgyulladásos beteget, véletlenszeren 100-at megmteni, és megvárni, amíg 99 gyógyultan hazamegy (nem 100-at mondtam, mert legyen a mtétnek is valamicske kockázata), 100-zal nem csinálni semmit, és megvárni, amíg 99 is az intenzív osztályra kerül perforált vakbéllel (nem 100-at mondtam, mert azért spontán is lehessen meggyógyulni), és voila, meg is van az igen magas bizonyítóerej bizonyítékunk a vakbélmtét hatásosságára! Egész érthetetlen módon nem tudok róla, hogy ezt bárki megcsinálta volna Vagy mondjuk kipróbálta-e bárki randomizált kísérletben, hogy ha nagy magasságban kiesünk egy repülgépbl, akkor jót tesz-e, ha van nálunk ejterny? Bocsánat, ez utóbbi kérdésre lehet pontos választ adni: Smith és szerztársa 2003-as cikkükben  a neves orvosi folyóirat, a British Medical Journal karácsonyi különszámában jelent meg  nagyon alapos irodalomkutatást végeztek a témában. Pontosan definiálták az expozíciót (ejternyvel rendelkezés szabadesés esetén) és a végpontot (halál, vagy komoly trauma  a traumatológiában általánosan használatos ISS sérüléssúlyossági pontszám 15-nél nagyobb  fellépése a földbecsapódáskor), rendkívül átfogó, több adatbázisra kiterjed, pontosan dokumentált irodalomkeresést végeztek, majd arra a megdöbbent eredményre jutottak, hogy elképeszt módon egyetlen egy vizsgálat sem volt, melyben embereket repülgépbl dobáltak volna ki, randomizáltan ellátva ket ejternyvel és vizsgálva a végpontot! Azaz, mondják a szerzk  nyilván a kísérletek mindenekfeletti mivoltát hirdetkön gúnyolódva  igazából nem tudhatjuk, hogy jót tesz-e, ha van nálunk ejterny, ha kiesünk egy repülgépbl A másik dolog, amit mindig észben kell tartani: ha el kell döntenünk egy kérdést, akkor  természetesen  az összes rendelkezésre álló bizonyítékot fel kell használnunk. A második kifejezés, amit nagyon szeretek: a bizonyítékok összessége szemlélet. Nem lehet kiragadni egy konkrét kutatást, különösen, ha rengeteg készült a számunkra érdekes kérdés vizsgálatára. Márpedig egy sor ilyen témakör van; ezekben az esetekben az, hogy egy konkrét kutatás mit talált, nem sokat jelent. Szoktam mondani, hogy számos kérdés esetében, ha kapok öt percet és egy számítógépet internetkapcsolattal, akkor legalább egy kutatást minden állításra és az ellenkezjére is találok El kell tehát felejteni az olyan szalagcímeket, hogy A legújabb kutatás bizonyította, hogy  nem az az érdekes, hogy a legújabb mit bizonyított, hanem az, hogy összességében mit bizonyítanak a kutatások! Hasonlóan félrevezetések alapjai lehetnek az olyan mondatok  noha elsre nagyon tudományosnak látszódnak!  miszerint ez tehát ilyen hatást okoz [Doe, 2016] (különösen laikusok megtévesztésére alkalmas ez, akik hajlamosak azt gondolni, hogy mivel ez egy ilyen komolyan kinéz, tudományos hivatkozással ellátott állítás, akkor így kell legyen  ha egyszer itt az alátámasztó kutatás!) Valójában azonban ez nem sokat jelent, még ha Doe tényleg ezt is találta, azonban 20 másik kutatás meg az ellenkezjét. TODO Ez a fejezet az Interpress Magazinban (IPM) megjelent cikksorozatom els néhány részének rövidített, szerkesztett változata. "]]
